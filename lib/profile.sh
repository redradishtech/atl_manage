#shellcheck shell=bash
# Defines profile functions: atl_load, atl_unload, atl_freeze, atl_list, and aliases (cda, cdm, cdp, etc).

# set -a exports all functions, which is necessary for subshells (e.g. standlone scripts) to be able to invoke e.g. atl_load or atl_freeze. Unfortunately it has the strange effect of breaking the shell ('Argument list too long') after autocomplete is triggered:
#
# root@jturner-desktop:~/redradishtech/clients/# jj --^C
# bash: /usr/local/bin/direnv: Argument list too long
# bash: /usr/bin/date: Argument list too long
# bash: /usr/bin/hostname: Argument list too long
#set -a

declare -A help
help[ATL_VER]="App version. For Git apps, see ATL_VER_HASH for the actual git revision used."
help[ATL_DATADIR_VERSIONED]="Whether ATL_DATADIR is a versioned directory, allowing quick rollback on failed upgrades. Only needed for apps where a new version might modify ATL_DATADIR data in a backwards-incompatible way"
help[ATL_DATADIR_BASE]="Base directory below which runtime data (home directory, backups) is stored"
help[ATL_DATADIR]="App home/data directory. Equal to ATL_DATADIR_BASE + (ATL_DATADIR_VERSIONED ? ATL_VER : '') + (ATL_MULTITENANT ? ATL_TENANT : ''). "
help[ATL_DATADIR_NEW]="Same as ATL_DATADIR, but for the being-installed ATL_NEWVER version of the app"
help[ATL_DATALOGDIR]="Where logs generated directly by the application are stored, in ATL_DATADIR. Distinct from logs generated by auxiliary scripts, and Tomcat, in ATL_LOGDIR"
help[ATL_TENANT]="A single app deployment with a wildcard DNS can run multiple 'tenants', each with their own database and data directory. By default, the 'tenant' is ATL_SHORTNAME"
help[ATL_USER]="App runtime user. Should have read-only access to \$ATL_APPDIR/app, write access to \$ATL_DATADIR and \$ATL_DATABASE. If multitenant where there is no single runtime user, this must still be set to a representative account (the owner of ATL_GROUP, which all actual runtime users will belong to))"
help[ATL_GROUP]="ATL_GROUP members get read-only access to ATL_USER files"

help[ATL_SERVICES_USER]="Auxiliary services (backup, monitoring, etc) run as this user, which is a member of ATL_GROUP, and has (at least) read-only access to ATL_DATADIR, the database, and read-only access to some config files (e.g. in \$ATL_APPDIR/backups/) that ATL_USER doesn't have. Has write access to \$ATL_LOGDIR, \$ATL_BACKUP_ROOT. Defaults to root"
help[ATL_SERVICES_GROUP]="ATL_SERVICE_GROUP members get read-only access to output of ATL_SERVICES_USER, e.g. log files and backups. Defaults to 'adm'"
help[ATL_APPDOMAIN]="The domain the app is deployed as (e.g. 'jira.company.com') for single-tenant; the base app domain (e.g. 'easyjethro.com.au') for multitenant"
help[ATL_BASEDOMAIN]="Domain above the app. E.g. 'company.com' for 'jira.company.com'"
help[ATL_BASEURL]="App's public base URL, e.g. https://jira.example.com"
help[ATL_BASEURL_INTERNAL]="App's internal base URL, e.g. http://jira.internal:8080. Note there is also an internal URL for proxies (e.g. http://jira.internal:80) but it is currently unnamed"
help[ATL_BASEURL_IS_AUTH_PROXIED]="Set to true if ATL_BASEURL has some external authentication layer (e.g. Cloudflare Access or HTTP Basic auth) which will prevent this host accessing it"
help[ATL_PRODUCT_RUNTIME_TECHNOLOGY]="Specifies the required runtime (java, php etc), runtime vendor (openjdk, azul etc) and version (11, 7.4 etc)"

# PS1 is only define if we're manually debugging, sourcing this .sh file by hand
if [[ -v _profile_sourced && ! -v PS1 ]]; then
	#echo >&2 "profile.sh already sourced. Skipping"
	return
else
	#echo >&2 "Sourcing profile.sh"
	_profile_sourced=1
fi
# Try to only source logging.sh when needed as it messes up subshells
#shellcheck source=/opt/atl_manage/lib/logging.sh
#. "$ATL_MANAGE/lib/logging.sh"
#shellcheck source=/opt/atl_manage/lib/version.sh
. "$ATL_MANAGE/lib/version.sh"

#shellcheck source=/opt/atl_manage/lib/prompt.sh
. "$ATL_MANAGE/lib/prompt.sh"
# ## Loads relevant ATL_* variables, based on the application 'profile' the user indicates they want to work with
## The current implementation sources various shell scripts in /etc/atlassian_app_profiles (based on the hostname), and then defines a whole lot more default variables.
# Note that atl_profile is SOURCED, so there is no hashbang. Se need to explicitly set -eu if we need it

_atl_originaldir="$(pwd)" # We are sourced, so any directory changes are persistent. Record our PWD so that the _err() function can return to it

atl_unload() {
	# We added $ATL_APPDIR/bin to the start of our PATH in atl_load - now remove it so that switching from profile A to profile B doesn't leave A's scripts in PATH
	#echo "Stripping ${ATL_APPDIR}/bin: from $PATH"
	export PATH="${PATH#${ATL_APPDIR}/bin:}"
	_atl_unset_vars # Unset ATL_* vars
	ATL_NOEMAIL=unset
	# Remove dynamic prompt
	if [[ -n ${PROMPT_COMMAND_ORIG:-} ]]; then
		PROMPT_COMMAND="$PROMPT_COMMAND_ORIG"
	fi
}

_getprofilepath() {
	# Now find the first 'profile' that matches our entered text. E.g. if 'jira' is entered, and 'jira-staging.foo.com' and 'jira.foo.com' are available, pick 'jira.foo.com'.
	# We can't use 'sort' to get the right entry. Sort is weird, e.g.:
	#  echo -e "jira-staging.d\njira.d" | sort -r
	# returns jira-staging first, but:
	#  echo -e "jira-staging.x\njira.x" | sort -r
	# returns jira.x first
	# So we pick the shortest profile filename
	# The -L is so /etc/atlassian_app_profiles/redradishtech/ can be a symlink

	read -r _ globstar <<<"$(shopt globstar)"
	[[ $globstar = on ]] || { echo >&2 "Please 'shopt -s globstar' in the calling shell"; return 1; }

	local wildcarded
	wildcarded="\*.${1#*.}*" #
	cd "$ATL_PROFILEDIR" || {
		_err "Missing profile dir: $ATL_PROFILEDIR"
		return 1
	}
	profilefile=$(find -L . \( -name "$1*" -or -name "$wildcarded" \) -not -iwholename "*.hg*" -not -iwholename "*/plugindata/*" -not -name .meta -not -iwholename "*\[*\]*" -type f -printf "%P\n" | awk '{print length, $0}' | sort -n -s | cut -d" " -f2- | head -1)
	test -f "$profilefile" || {
		_err "No profile matching '$1' found. Searched for $ATL_PROFILEDIR/**/{$1*,$wildcarded}"
		return 1
	}
	echo "$profilefile"
}

# Given a user-entered profile selection string (e.g. 'jira', 'jira.example.com'), and the matching profile file ('./jira.example.com'), return the inferred ATL_LONGNAME ('jira.example.com'). Also support wildcard profile files ('./*.easyjethro.com.au'), where ATL_TENANT becomes the '*' part, and ATL_LONGNAME the remainder.
_set_longname_and_tenant_from_path() {
	local selector="$1"		# 'j', 'jir', 'jira.example.c', etc
	local profilepath="$2"	# './jira.example.com', 'easyjethro/*.example.com' etc
	local profilefile="$(basename "$profilepath")"
	if [[ "${profilefile:0:2}" = '*.' ]]; then     # We matched a wildcard profile
		export ATL_LONGNAME="${profilefile:2}"       # Strip '*.' from '*.example.com', yielding the longname 'example.com'
		export ATL_TENANT="${selector%%.*}"
		#remainder="${profilefile:1}"                 # strip the '*' from '*.example.com', yielding '.example.com' '.example.c' etc
		# This didn't work, as $selector does not necessarily contain all of $remainder
		#export ATL_TENANT="${selector%${remainder}}" # Strip $remainder ('.example.com') from the selector ('foo.example.com'), yielding the tenant name
	else
		# Non-wildcard profile. The LONGNAME is the filename
		export ATL_LONGNAME="$profilefile"
		unset ATL_TENANT
	fi
}

# Variables that change if ATL_TENANT changes. These are not set by 'atl_freeze'. Other scripts (currently _ej_unload.sh) may use this variable.
# In string form, so the variable can be inherited by subshells
export ATL_TENANT_SPECIFIC_VARS="ATL_TENANT
	ATL_DATABASE
	ATL_DATABASE_USER
	ATL_DATABASE_PASSWORD
	ATL_USER
	ATL_DATADIR
	ATL_DATADIR_NEW
	ATL_DATALOGDIR
	ATL_FQDN
	ATL_BASEURL"

# Vars that only make sense when a particular tenant is loaded.
export ATL_TENANT_ONLY_VARS="ATL_TENANT
	ATL_DATABASE
	ATL_DATABASE_USER
	ATL_DATABASE_PASSWORD
	ATL_USER
	ATL_DATADIR
	ATL_DATADIR_NEW
	ATL_DATALOGDIR
	ATL_FQDN
	ATL_BASEURL"

atl_load() {

	_err() {
		echo >&2 "$*"
		cd "$_atl_originaldir"
		return 1
	}

	_atl_sourcefile() {
		local file="$1"
		local reason="${2:-}"
		if [[ -f $file ]]; then
			# Why did we 'readlink -f' this? It's annoying if all files are symlinked to 'common'
			#log "Sourcing $(readlink -f "$file")				($reason)"
			#log "Sourcing $PWD/$file				($reason)"
			# Note the ./, since we can't rely on the caller putting '.' first in the path (I had /usr/local/bin/jira sourced by accident once)
			# shellcheck disable=SC1090
			source "./$file"
			# Keep a persistent record of which files contributed to our variables. This is used later by atl_upgrade_switchver to modify ATL_VER
			ATL_PROFILEFILES_SOURCED_ARR+=("$file")
			ATL_PROFILEFILES_SOURCED_ABSOLUTE_ARR+=("$(readlink -e -- "$file")")
			# Note this is a space-separated string because bash arrays cannot be exported, so atl_upgrade_switchver couldn't see it
			export ATL_PROFILEFILES_SOURCED="${ATL_PROFILEFILES_SOURCED_ARR[*]}"
			export ATL_PROFILEFILES_SOURCED_ABSOLUTE="${ATL_PROFILEFILES_SOURCED_ABSOLUTE_ARR[*]}"
		else
			# FIXME: On MacOS this really is black. Pick a better colour, or perhaps do not rely on ANSI definitions
			#
			echo -e >&2 "${DISABLED}Not found: ${file}		($reason)${DEFAULT}"
		fi
	}

	_atl_source_profiles() {
		# TODO: Reimplement ATL_PROFILEDIR to work something like udev (https://wiki.debian.org/udev).
		local phase="$1"
		shift # 'pre' or 'post', indicating before or after default variables are set. Also 'global' for profile-independent global vars
		cd "$ATL_PROFILEDIR" || {
			_err "Missing profile dir: $ATL_PROFILEDIR"
			return 1
		}

		case "$phase" in
		global)
			# If we have a server with profiles for multiple companies: $ATL_PROFILEDIR/org1/*, $ATL_PROFILEDIR/org2/*, etc, it is useful to keep server-wide variables below the orgN/* directories so it isn't repeated.
			_atl_sourcefile "[host=${HOSTNAME%%.*}]" "server-specific, app-agnostic settings"
			;;

		pre)
			#shellcheck source=/opt/atl_manage/lib/common.sh
			. "$ATL_MANAGE/lib/common.sh"
			[[ -n "$1" ]] || {
				echo >&2 "Usage: _atl_source_profiles pre PROFILENAMEPART"
				return 1
			}
			# Given 'jira', profilefile could be 'jira.company.com'
			profilefile="$(_getprofilepath "$1")" || return $?
			_set_longname_and_tenant_from_path "$1" "$profilefile"
			local dir
			dir="$(dirname "$profilefile")"
			#log "Got app file ${profilefile:-}"
			#log "Sourcing profile from $profilefile"
			export ATL_LONGNAME
			_atl_sourcefile "$profilefile"
			[[ -v ATL_SHORTNAME ]] || {
				_err "Please define ATL_SHORTNAME in $profilefile"
				return 1
			}
			# Disable this: if we have an instance called 'jira-staging' or something then it's fair to set ATL_ROLE in the main profile
			#[[ ! -v ATL_ROLE ]] || { _err "ATL_ROLE should be set in $PWD/$dir/[host=$HOSTNAME][name=$ATL_SHORTNAME] or $PWD/$dir/[host=$HOSTNAME], not $PWD/$profilefile, because roles are server-specific."; return 1; }

			# Don't depend on /etc/machine-info any more, because we want the non-presence of ATL_ROLE to indicate that the profile isn't valid.
			# This overrides generic profiles, but not the profile-specific ones. This allows us to have a sandbox on the same machine as a standby prod
			#if [[ -f /etc/machine-info ]]; then
			#	. /etc/machine-info
			#	if [[ -v DEPLOYMENT ]]; then
			#		if [[ $DEPLOYMENT = production ]]; then DEPLOYMENT=prod; fi
			#		log "Setting role from /etc/machine-info (see hostnamectl(5))"
			#		# Ugly hack. We need to store ATL_ROLE ('standby') separately from ATL_STATE ('pre-production', 'maintenance'). For now we stuff both these facets into ATL_ROLE and rely on =~ to check for both
			#		# Note that ATL_ROLE may not even be set until here
			#		if [[ ${ATL_ROLE:-} =~ standby ]]; then ATL_ROLE="$ATL_ROLE $DEPLOYMENT"; else ATL_ROLE="$DEPLOYMENT"; fi
			#	fi
			#
			#	fi
			_atl_sourcefile "$dir/[host=${HOSTNAME%%.*}]" "server-specific, app-agnostic settings"
			_atl_sourcefile "$dir/[host=${HOSTNAME%%.*}][name=$ATL_SHORTNAME]" "app- and server-specific settings. On staging set ATL_LONGNAME/ATL_PARENT_LONGNAME here, or in [host=$HOSTNAME]"

			# Pre-defaults. We source these again post-defaults
			# 6/Apr/20: don't remember why we did this.
			#_atl_sourcefile "$dir/[name=${ATL_SHORTNAME}]"	"Variable-dependent settings	(pre-defaults)"
			#_atl_sourcefile "$dir/[org=$ATL_ORGANIZATION]" "Organization-specific settings	(pre-defaults)"
			#_atl_sourcefile "$dir/[org=$ATL_ORGANIZATION]"/"[name=$ATL_SHORTNAME]	(pre-defaults)"
			#cd "$olddir" || true; # $$olddir might be a deleted directory (as in the case of $ATL_DATADIR/previous during atl_upgrade_switchver -r), in which case, soldier on
			;;
		post)
			local dir="$(dirname "$profilefile")"
			#log "In post. pwd=$PWD, ATL_SHORTNAME=${ATL_SHORTNAME:-}, ATL_ORGANIZATION=${ATL_ORGANIZATION:-}, ATL_FQDN=${ATL_FQDN}, dir=${dir:-}"
			if [[ -v ATL_SHORTNAME ]]; then [[ ! -f .$ATL_SHORTNAME-post ]] || {
				_err "Please rename .$ATL_SHORTNAME-post to [name=$ATL_SHORTNAME]"
				return 1
			}; fi
			# We can only source these post-defaults because only then are the requisite variable names (ATL_SHORTNAME, ATL_ORGANIZATION) known.
			[[ -v ATL_SHORTNAME ]] && _atl_sourcefile "$dir/[name=${ATL_SHORTNAME}]" "Variable-dependent settings	Set ATL_BANNERTEXT here"
			[[ -v ATL_ORGANIZATION ]] && _atl_sourcefile "$dir/[org=$ATL_ORGANIZATION]" "Organization-specific settings"
			[[ -v ATL_ORGANIZATION && -v ATL_SHORTNAME ]] && _atl_sourcefile "$dir/[org=$ATL_ORGANIZATION]/[name=$ATL_SHORTNAME]"

			# While we transition from ATL_PRODUCT to ATL_APPLICATION, make both available so patchqueues don't break
			_atl_sourcefile "$dir/[product=$ATL_PRODUCT]" "Product-specific settings" # E.g. Jethro always wants ATL_PRODUCT_RUNTIME_TECHNOLOGY=php. We should create a $ATL_MANAGE/app_profiles/ for common stuff.
			return
			;;
			#upgrade)
			#	# Rename any obsolete variables
			#	#find "$ATL_PROFILEDIR" -not \( -path "*/\.hg" -prune \) -not \( -path "*/plugindata" -prune \) -type f -print0 | xargs -0 --no-run-if-empty grep -Z -l ATL_APPLICATION | xargs -0 --no-run-if-empty perl -i -pe 's/ATL_APPLICATION/ATL_PRODUCT/g'
			#	;;
		esac
	}

	_atl_vars_setme() {
		set | grep ^ATL_ | grep setme | perl -pe 's/^(ATL_.*?)=.*/\1/g' | xargs --no-run-if-empty || :
	}

	unset_setme_vars() {
		unset $(_atl_vars_setme)
		#	unset PROMPT_COMMAND
		# Unfortunately the original PS1 is lost. Set it to the default from /etc/bash.bashrc
		# shellcheck disable=SC2154
		export PS1='${debian_chroot:+($debian_chroot)}\u@\h:\w\$ '
	}

	## FIXME: copied to events/install-post/isso
	# Print the next available user UID/GID.
	# Usage:
	# _getnextid <user|group> [ [--reserve N] | [--look-backwards N] ]
	# If passed '--reserve N', then an integer N is added to the next available UID. This lets the caller 'reserve' N UIDs for sub-services
	# If passwd '--use-reserved N', then up to N UIDs earlier than $ATL_USER's are examined (in decreasing order), and will be used if free. This is intended to be used by sub-services when the parent service has used --reserve N. If none of the N UIDs prior to $ATL_USER's UID are free, then the next free UID is chosen.
	_getnextid() {
		case "$1" in
		user) entity=passwd ;;
		group) entity=group ;;
		*) _err "Illegal arg. Usage: _getnextid <user|group>: $1" ;;
		esac
		shift

		if [[ $1 = --use-reserved ]]; then
			shift
			local -r backcount=$1
			local uid="$(id -u "$ATL_USER")"
			for i in $(seq 1 "$backcount"); do
				uid=$((uid - i))
				if getent $entity $((uid - i)); then
					echo >&2 "Hooray, we found an ID ($uid) in the reserved set of 10 for $ATL_USER"
					echo "$uid"
					return
				fi
			done
			log "No reserved set of UIDs; using next available UID"
			getent $entity | awk -F: '($3>600) && ($3<10000) && ($3>maxuid) { maxuid=$3; } END { print maxuid+1; }'
			return
		fi
		if [[ $1 = --reserve ]]; then
			shift
			local reserved="$1"
		else
			local reserved=0
		fi
		getent passwd | awk -F: '($3>600) && ($3<10000) && ($3>maxuid) { maxuid=$3; } END { print maxuid+'$((1 + reserved))'; }'
	}

	# Thows an error if something is amiss with the currently loaded profile variables.
	# Note that because atl_profile is SOURCED, 'fail' doesn't exit(), but just returns with an exit code, so we need to explicitly 'return'
	_atl_validate_profile() {

		if [[ $1 = global ]]; then
			return
		fi

		# Fail if there are any undefined variables.
		local setmevars="$(_atl_vars_setme)"
		if [[ -n "$setmevars" ]]; then
			echo "Profile errors:"
			for var in $setmevars; do
				if [[ ${!var} = setme ]]; then
					text="Please set"
				else
					text="${!var/setme:/}"
				fi
				printf "%-45s # %s\n" "$var" "$text"
			done
			export ATL_PROFILE_INCOMPLETE="$setmevars"
			return 1
		fi

		[[ -n ${ATL_LONGNAME+x} ]] || {
			_err "ATL_LONGNAME is unset"
			return $?
		}
		[[ -n ${ATL_SHORTNAME+x} ]] || {
			_err "ATL_SHORTNAME is unset"
			return $?
		}
		[[ -n ${ATL_ROLE+x} ]] || {
			_err "ATL_ROLE is unset. This generally means $ATL_LONGNAME should not be running on $HOSTNAME"
			return $?
		}
		[[ -v ATL_SERVER_ROLE ]] || {
			_err "ATL_SERVER_ROLE is unset. This must be set so monitoring of server-wide things, like load, know to tag themselves as production or staging. This is best done in a host-specific file: echo -e ATL_SERVER_ROLE=prod >> \$ATL_PROFILEDIR/'[host=$HOSTNAME]'"
			return $?
		}
		[[ ! -v ATL_PROFILE ]] || {
			_err "ATL_PROFILE (value '$ATL_PROFILE') is no longer kosher - replace it with ATL_SHORTNAME ('$ATL_SHORTNAME')"
			return $?
		}
		case "$ATL_PRODUCT_FULL" in
		jira* | confluence | crowd | bitbucket | jethro)
			if [[ $ATL_PRODUCT = jethro && $ATL_VER = tip ]] || ! is_valid_version_pattern "$ATL_VER" && [[ $ATL_PRODUCT != none ]]; then
				_err "Error in $ATL_PROFILEDIR/$ATL_LONGNAME ATL_VER: '$ATL_VER' does not look like a valid version (x.y.z format)"
				return $?
			fi
			# https://stackoverflow.com/questions/7832080/test-if-a-variable-is-set-in-bash-when-using-set-o-nounset
			if [[ ${ATL_NEWVER+x} ]] && ! is_valid_version_pattern "$ATL_NEWVER"; then
				_err "Error in $ATL_PROFILEDIR/$ATL_LONGNAME ATL_NEWVER: '$ATL_NEWVER' does not look like a valid version (x.y.z format)"
				return $?
			fi
			;;
		esac

		[[ -v ATL_PRODUCT_FULL ]] || {
			_err "Please define ATL_PRODUCT_FULL"
			return $?
		}
		echo "Checking what $ATL_PRODUCT_FULL matches"
		case "$ATL_PRODUCT_FULL" in
			jira-software) ;;
			jira-core) ;;
			jira-servicedesk) ;;
			confluence) ;;
			bitbucket) ;;
			fisheye) ;;
			crucible) ;;
			bamboo) ;;
			crowd) ;;
			postgresql) ;;
			jethro | jethro-jeff | jethro-tom) ;;
			invoiceninja) ;;
			website) ;;
			*) _err "Unknown ATL_PRODUCT_FULL in $ATL_PROFILEDIR/$ATL_LONGNAME: '$ATL_PRODUCT_FULL' (for JIRA use 'jira-core', 'jira-software' or 'jira-servicedesk')" ;;
		esac

		# ATL_UID/ATL_GID is required by atl_deploy. It could be made optional there, but backupmirror/sync_backup need it anyway to ensure staging envs use the same.
		# Inferring ATL_GID is always a bad idea. For genuinely 'floating' groups like www-data, use ATL_GID=$(getent group www-data | cut -d: -f3) in the profile
		#if [[ -v ATL_GROUP && ! -v ATL_GID ]]; then
		#	# ATL_GROUP is something like www-data for which we haven't explicity set ATL_GID
		#	ATL_GID="$(getent group $ATL_GROUP | cut -d: -f3)"
		#fi

		if [[ ! -v ATL_UID ]]; then
			local uid
			uid=$(id -u "$ATL_USER" 2>/dev/null)
			if [[ -v ATL_USER && -n $uid ]]; then
				_err "Please set ATL_UID. Suggested value: ATL_UID=$uid  # the uid of $ATL_USER (ATL_USER) on $HOSTNAME. Or avoid hardcoding with: ATL_UID=\"\$(id -u \"\$ATL_USER\")\""
				return $?
			else
				_err "Please set ATL_UID and ATL_USER"
				return $?
			fi
		fi

		if [[ ! -v ATL_GID ]]; then
			if [[ -v ATL_GROUP ]]; then
				local gid
				if gid=$(id -g "$ATL_GROUP" 2>/dev/null); then
					_err "Please set ATL_GID. Suggested value: ATL_GID=$gid  # the gid of $ATL_GROUP (ATL_GROUP) on $HOSTNAME. Or avoid hardcoding with: ATL_GID=\"\$(id -g \"\$ATL_GROUP\")\""
					return $?
				else
					_err "Please set ATL_GID and ATL_GROUP"
					return $?
				fi
			fi

			local gid
			if gid=$(id -g "$ATL_USER" 2>/dev/null); then
				warn "GID is unset, but ATL_USER has effective group $gid. Setting from that"
				ATL_GID=$gid
			else
				warn "GID is unset, and ATL_USER '$ATL_USER' has no group"
				if [[ $ATL_ROLE = prod ]]; then
					_err "Please set ATL_GID. Suggested value: ATL_GID=$(_getnextid group --reserve 10)"
					return $?
				else
					_err "Please set ATL_GID to whatever value it has on the primary (non-$ATL_ROLE) instance, so it has the same id on this server"
					return $?
				fi
			fi
		fi

		# Ensure ATL_GID/ATL_GROUP are consistent
		if grouprec=$(getent group "$ATL_GID"); then
			# If ATL_GID already exists in /etc/groups, make sure it maps to ATL_GROUP
			if ! [[ $grouprec =~ ^$ATL_GROUP: ]]; then
				_err "ATL_GID/ATL_GROUP mismatch: ATL_GROUP is $ATL_GROUP, but group with ATL_GID=$ATL_GID is: $grouprec"
				return $?
			fi
		fi

		if [[ ! -v ATL_SERVICES_UID ]]; then
			# In load_profile_defaults we would have tried setting it to ATL_SERVICES_USER's uid if it existed; it must not, so don't try
			_err "Please set ATL_SERVICES_UID. Suggested value: ATL_SERVICES_UID=$(_getnextid user --reserve 10)"
			return $?
		fi

		if [[ ! -v ATL_SERVICES_GID ]]; then
			# In load_profile_defaults we would have tried setting it to ATL_SERVICE_GROUP's gid if it existed; it must not, so don't try
			_err "Please set ATL_SERVICES_GID and ATL_SERVICES_GROUP"
			return $?

			if id -g "$ATL_SERVICES_USER" >/dev/null; then
				warn "GID is unset, but ATL_SERVICES_USER has a group. setting from that"
				ATL_SERVICES_GID=$(id -g "$ATL_SERVICES_USER")
				warn "Auto-setting ATL_SERVICES_GID to $ATL_SERVICES_GID"
			else
				warn "GID is unset, and ATL_SERVICES_USER $ATL_SERVICES_USER has no group"
				if [[ $ATL_SERVICES_ROLE = prod ]]; then
					_err "Please set ATL_SERVICES_GID. Suggested value: ATL_SERVICES_GID=$(_getnextid group --reserve 10)"
					return $?
				else
					_err "Please set ATL_SERVICES_GID to whatever value it has on the primary (non-$ATL_SERVICES_ROLE) instance, so it has the same id on this server"
					return $?
				fi
			fi
		fi

		# Ensure ATL_UID/ATL_USER are consistent
		if userrec=$(getent passwd "$ATL_UID"); then
			if ! [[ $userrec =~ ^$ATL_USER: ]]; then
				_err "ATL_UID/ATL_USER mismatch: ATL_USER is $ATL_USER, but user with ATL_UID=$ATL_UID is: $userrec"
				return $?
			fi
		fi

		# Ensure ATL_USER's primary group is ATL_GROUP
		if usergroup="$(id --group --name "$ATL_USER")"; then
			if [[ ! ${ATL_MULTITENANT:-} == true ]]; then
				# For multitenant we might want to deploy as ATL_USER=root, ATL_GROUP=jethro or whatever
				[[ $ATL_GROUP == "$usergroup" ]] || {
					_err "User '$ATL_USER' has primary group with '$usergroup', not $ATL_GROUP as 'ATL_GROUP' indicates it should"
					return $?
				}
			fi
		fi

		# Ensure ATL_SERVICES_GID/ATL_SERVICES_GROUP are consistent
		if grouprec=$(getent group "$ATL_SERVICES_GID"); then
			# If ATL_SERVICES_GID already exists in /etc/groups, make sure it maps to ATL_SERVICES_GROUP
			if ! [[ $grouprec =~ ^$ATL_SERVICES_GROUP: ]]; then
				_err "ATL_SERVICES_GID/ATL_SERVICES_GROUP mismatch: ATL_SERVICES_GROUP is $ATL_SERVICES_GROUP, but group with ATL_SERVICES_GID=$ATL_SERVICES_GID is: $grouprec"
				return $?
			fi
		fi

		# Ensure ATL_SERVICES_UID/ATL_SERVICES_USER are consistent
		if userrec=$(getent passwd "$ATL_SERVICES_UID"); then
			if ! [[ $userrec =~ ^$ATL_SERVICES_USER: ]]; then
				_err "ATL_SERVICES_UID/ATL_SERVICES_USER mismatch: ATL_SERVICES_USER is $ATL_SERVICES_USER, but user with ATL_SERVICES_UID=$ATL_SERVICES_UID is: $userrec"
				return $?
			fi
		fi

		# Ensure ATL_SERVICES_USER's primary group is ATL_SERVICES_GROUP
		local sugroup
		if sugroup="$(id --group --name "$ATL_SERVICES_USER" 2>/dev/null)"; then
			[[ $ATL_SERVICES_GROUP == "$sugroup" ]] || {
				_err "User '$ATL_SERVICES_USER' has primary group with '$sugroup', not $ATL_SERVICES_GROUP as 'ATL_SERVICES_GROUP' indicates it should"
				return $?
			}
		fi

		if [[ $ATL_SERVICES_USER != root ]]; then
			[[ $ATL_SERVICES_USER != "$ATL_USER" ]] || {
				_err "ATL_SERVICES USER ($ATL_SERVICES_USER) must not be ATL_USER ($ATL_USER), because although services need access to files owned by ATL_USER, ATL_USER should not be able to access service config files (.env, backups/rsnapshot.conf etc). Normally ATL_SERVICES_USER should be set to 'root'"
				return $?
			}
			local sugroups
			if id -g "$ATL_GROUP" &>/dev/null; then # We might have just loaded the profile and not yet created the group
				if sugroups=$(id --groups --name "$ATL_SERVICES_USER" 2>/dev/null); then
					echo "$sugroups" | grep -qw "$ATL_GROUP" || {
						_err "We expect ATL_SERVICES_USER ($ATL_SERVICES_USER) to be a member of ATL_GROUP ($ATL_GROUP), so it is guaranteed read-only access to ATL_USER files. To fix, usermod -aG \"$ATL_GROUP\" \"$ATL_SERVICES_USER\""
						return $?
					}
				fi
			fi
		fi

		for role in PRIMARY STANDBY; do
			if [[ $role = PRIMARY ]]; then local otherrole=STANDBY; else local otherrole=PRIMARY; fi
			local marker=ATL_REPLICATION_${role}
			local ourhost=ATL_REPLICATION_${role}_HOST
			local otherhost=ATL_REPLICATION_${otherrole}_HOST
			local bad_marker=ATL_REPLICATION_${otherrole}
			if [[ -v $marker ]]; then
				[[ ${!marker} = true ]] || _err "$marker is defined but its value is ${!marker}, not 'true' as expected"
				[[ ! -v $bad_marker ]] || _err "Cannot have both $marker and $bad_marker defined"
				[[ -v $ourhost ]] || _err "$marker is defined, but $ourhost is not. We need both $otherhost var and $ourhost defined"
				[[ -v $otherhost ]] || _err "$marker is defined, then $otherhost must be defined too"
			fi
		done
		# Backup mirror sanity checks:
		for role in SOURCE MIRROR; do
			if [[ $role = SOURCE ]]; then local otherrole=DESTINATION; else local otherrole=SOURCE; fi
			local marker=ATL_BACKUPMIRROR_${role}
			local ourhost=ATL_BACKUPMIRROR_${role}_HOST
			local otherhost=ATL_BACKUPMIRROR_${otherrole}_HOST
			local bad_marker=ATL_BACKUPMIRROR_${otherrole}
			if [[ -v $marker ]]; then
				[[ ${!marker} = true ]] || _err "$marker is defined but its value is ${!marker}, not 'true' as expected"
				[[ ! -v $bad_marker ]] || _err "Cannot have both $marker and $bad_marker defined"
				[[ -v $ourhost ]] || _err "If $marker is defined, but $ourhost is not. We need both $otherhost var and $ourhost defined"
				[[ -v $otherhost ]] || _err "If $marker is defined, then $otherhost must be defined too"
			fi
		done

		#if [[ -v ATL_MULTITENANT && $ATL_MULTITENANT == true && -f $ATL_APPDIR/.env/ATL_DATADIR ]]; then
		#	warn "Deleting $ATL_APPDIR/.env/ATL_DATADIR which should not be stored when ATL_MULTITENANT = true"
		#	rm -f "$ATL_APPDIR"/.env/ATL_DATADIR
		#fi

		if [[ -v ATL_TRUSTED_IPS && "$ATL_TRUSTED_IPS" != "127.0.0.1" ]]; then
			warn "Please replace ATL_TRUSTED_IPS («$ATL_TRUSTED_IPS») with ATL_ADMINISTRATOR_IPS («$ATL_ADMINISTRATOR_IPS»): perl -i -pe 's/ATL_TRUSTED_IPS/ATL_ADMINISTRATOR_IPS/g/' $ATL_PROFILEDIR/**"
		fi
		[[ ! -v ATL_APPLICATION_FULL ]] || warn "ATL_APPLICATION_FULL is obsolete. Please use ATL_PRODUCT_FULL (${ATL_PRODUCT_FULL:-}) instead"
		[[ ! -v ATL_APPLICATION ]] || warn "ATL_APPLICATION is obsolete. Please use ATL_PRODUCT (${ATL_PRODUCT:-}) instead"
		[[ ! -v ATL_APPLICATION_CAPITALIZED ]] || warn "ATL_APPLICATION_CAPITALIZED is obsolete. Please use ATL_PRODUCT_CAPITALIZED (${ATL_PRODUCT_CAPITALIZED:-}) instead"
		[[ ! -v ATL_EMAIL_INCOMING_USERNAME ]] || warn "ATL_EMAIL_INCOMING_USERNAME is obsolete. We no longer use fetchmail to fetch from an arbitrary mailbox, but rather rely on GMail pushing email to Postfix on our subdomain"
		[[ ! -v ATL_EMAIL_INCOMING_PASSWORD ]] || warn "ATL_EMAIL_INCOMING_PASSWORD is obsolete. We no longer use fetchmail to fetch from an arbitrary mailbox, but rather rely on GMail pushing email to Postfix on our subdomain"

	}

	# export every variable beginning with ATL_
	_atl_export_vars() {
		# 'sensitive' vars are things like API tokens, SSH private keys. Is having these things in our bash environment (note: the operator's, not the app's) a security risk? I don't think so, and atl_replacetokens currently assumes they are there, so for now sensitive and nonsenstive vars are all exported. An alternative would be to not export sensitive vars, and source them on demand from .env_admin, but currently I like the simplicity of having `env` the definitive source of ATL_ vars.
		# shellcheck disable=SC2046
		export $(_atl_vars_nonsensitive) $(_atl_vars_sensitive)
	}

	# Allow ${variables} in variable values. This is a hack necessary because we sometimes want to define variables in terms of other variables not yet defined. E.g. ATL_SSLCERTFILE='${ATL_APPDIR}/apache2/cert.pem'
	_atl_resolve_vars() {
		for v in $(_atl_vars_nonsensitive) $(_atl_vars_sensitive); do
			local orig="$v"
			if [[ ${!v} =~ '${' ]]; then
				#local evalme="$v=${!v@Q}"
				local evalme="$v=\"${!v}\""
				echo >&2 "Late-resolving expression: $evalme"
				eval "$evalme"
				if [[ ${!v} =~ '$' ]]; then
					echo >&2 "Unresolved variable in $v: ${!v}"
					return 1
				else
					echo >&2 "Late-resolved $v=${!v}"
				fi
			fi
		done
	}

	_atl_variable_default_values() {
		load_global_defaults() {
			#log "Loading default values"
			# If we notice here that a variable isn't set, but must be, default its value to 'setme' or 'setme:<explanation>', and we will handle it after the 'post' phase has happened (possibly setting the variable)

			# Global profile-independent variables

			if [[ -n ${ATL_PROFILEDIR:-} && ! -d $ATL_PROFILEDIR ]]; then echo >&2 "ATL_PROFILEDIR $ATL_PROFILEDIR missing"; fi

			ATL_ROLE=${ATL_ROLE:-setme}
			# The NTP server to check our date against. For chrony (the default) this should be internal
			ATL_NTP_HOST="${ATL_NTP_HOST:-internal}"

			ATL_WEBSERVER=${ATL_WEBSERVER:-apache2}

			# Remove deprecated ATL_TRUSTED_IPS some time after Aug 22
			ATL_ADMINISTRATOR_IPS=${ATL_ADMINISTRATOR_IPS:-127.0.0.1}
			ATL_TRUSTED_IPS=${ATL_ADMINISTRATOR_IPS}

			# Perhaps this should be renamed to ATL_MONITORING_NOTIFICANTS
			ATL_MONITORING_TYPES="${ATL_MONITORING_TYPES:-"${ATL_MONITORING:-nagios4}"}"
			if [[ -v ATL_MONITORING ]]; then
				warn "ATL_MONITORING is obsolete. Please replace usage with ATL_MONITORING_TYPES. For now, ATL_MONITORING_TYPES has been set to the ATL_MONITORING value ($ATL_MONITORING_TYPES)"
			else
				# For backwards-compat
				ATL_MONITORING="$(echo "$ATL_MONITORING_TYPES" | grep -oP "(nagios\d|icinga\d?)")"  # Extract out the local monitoring system
			fi

			ATL_MONITORING_MAILQUEUE_WARN=${ATL_MONITORING_MAILQUEUE_WARN:-1}
			ATL_MONITORING_MAILQUEUE_CRITICAL=${ATL_MONITORING_MAILQUEUE_CRITICAL:-5}
			ATL_MONITORING_MAILQUEUE_BOUNCES=${ATL_MONITORING_MAILQUEUE_BOUNCES:-0}
			# I frequently see up to 3 deferred emails in a busy 200-user Jira mailqueue. 5 in a non-busy system would indicate a problem
			ATL_MONITORING_MAILQUEUE_DEFERRED=${ATL_MONITORING_MAILQUEUE_DEFERRED:-5}
			ATL_MONITORING_WEBSERVER_FREESLOTS_WARNING=20
			ATL_MONITORING_WEBSERVER_FREESLOTS_CRITICAL=10

			# Subset of (more important) services to bother healthchecks.io about. See $ATL_MANAGE/monitoring/notify_all_monitoring
			ATL_MONITORING_HEALTHCHECKS_SERVICES="${ATL_MONITORING_HEALTHCHECKS_SERVICES:-backup-tarsnap-fresh backup-rsnapshot-fresh}"

			# Encrypt using the key in the homedir, if present, or the key defined in the profile, or the redradish default key otherwise.
			if [[ -v ATL_DATADIR && -f "${ATL_DATADIR}/backup.age-key" ]]; then
				echo >&2 "Using AGE public key in ATL_DATADIR"
				ATL_ENCRYPTION_AGE_PRIVATE_KEYFILE="$ATL_DATADIR/backup.age-key"
				ATL_ENCRYPTION_AGE_PUBLIC_KEY="$(age-keygen -y "$ATL_DATADIR/backup.age-key")"
			else
				# Allow overriding in a profile file
				ATL_ENCRYPTION_AGE_PUBLIC_KEY=${ATL_ENCRYPTION_AGE_PUBLIC_KEY:-age1zcudk7pk3p6dk675ynt2ddqtzte67tltpyp8x0kt5ghuxmshh43q77wzre}
				ATL_ENCRYPTION_AGE_PRIVATE_KEYFILE="${ATL_ENCRYPTION_AGE_PRIVATE_KEYFILE:-keepass://redradishpasswords/age-secret-key}"
			fi
		}

		load_profile_defaults() {

			# It would be nice if we could just let ATL_VER be SemVer if the user wants, or git sourcing demands, but we have this problem that '2.32.1-dev+b5191cb' s not a valid path component in ZFS (https://docs.oracle.com/cd/E23823_01/html/819-5461/gbcpt.html). AtlManage heavily depends on the notion of versioned directories, e.g. $ATL_APPDIR/<version>.
			# One solution (not implemented here) is to keep ATL_VER, but allow ATL_SEMVER to be specified instead, if needed. If ATL_SEMVER is specified, ATL_VER is derived from it (by chopping off the trailing +.*), and ATL_VER is used in paths. This could work, but adds confusion as to whether ATL_VER or ATL_SEMVER is to be used (and doubles all variably-modifying code).
			# Our solution is to have ATL_VER='2.32.1-dev' and then ATL_VER_HASH='b5191cb' for when more precision is needed, i.e. git-derived apps. This is a clean extension, but brings the risk of the two variables getting out of sync.

			[[ -v ATL_PRODUCT_FULL ]] || _err "Please set ATL_PRODUCT_FULL"
			case "$ATL_PRODUCT_FULL" in
			jira-*) ATL_PRODUCT=${ATL_PRODUCT_FULL%-*} ;;
			jethro-*) ATL_PRODUCT=${ATL_PRODUCT_FULL%-*} ;;   # jethro-jeff -> jethro
			*) ATL_PRODUCT=$ATL_PRODUCT_FULL ;; # confluence, crowd, etc.
			esac

			_load_profile_defaults_database() {
				ATL_DATABASE="${ATL_DATABASE:-$ATL_SHORTNAME}"
				ATL_DATABASE_TYPE=${ATL_DATABASE_TYPE:-postgresql} # Could also be 'postgresql-rds'. As long as the value starts with 'postgresql' it is considered postgres-compatible, and scripts like atl_psql will work. The part after the '-' is chopped off for the purpose of evaluating strings like /var/lib/postgresql or jdbc:postgresql://..
				ATL_DATABASE_USER=${ATL_DATABASE_USER:-$ATL_SHORTNAME}
				ATL_DATABASE_PASSWORD=${ATL_DATABASE_PASSWORD:-setme:Please set ATL_DATABASE_PASSWORD. If none is set, a good random choice is $(pwgen -1s)}
				ATL_DATABASE_HOST=${ATL_DATABASE_HOST:-localhost}
				# The external hostname of ATL_DATABASE_HOST. This is used by atlassian_documentationcopy.
				#ATL_DATABASE_PRIMARY_HOST=
				case $ATL_DATABASE_TYPE in
				*postgresql*)
					ATL_DATABASE_DRIVER=${ATL_DATABASE_DRIVER:-org.postgresql.Driver}
					ATL_DATABASE_PORT=${ATL_DATABASE_PORT:-5432}
					ATL_DATABASE_VERSION=${ATL_DATABASE_VERSION:-setme:Please set ATL_DATABASE_VERSION, probably in [host=$HOSTNAME]}
					ATL_DATABASE_CLUSTER=${ATL_DATABASE_CLUSTER:-main}
					ATL_DATABASE_SERVICENAME=postgresql
					ATL_DATABASE_SUPERUSER=${ATL_DATABASE_SUPERUSER:-postgres}
					ATL_DATABASE_SUPERPASSWORD=${ATL_DATABASE_SUPERPASSWORD:-setme:Please set Postgres "$ATL_DATABASE_SUPERUSER" user"'"s password, by running atl_install_database}
					;;
				mysql)
					ATL_DATABASE_DRIVER=${ATL_DATABASE_DRIVER:-com.mysql.jdbc.Driver}
					ATL_DATABASE_PORT=${ATL_DATABASE_PORT:-3306}
					ATL_DATABASE_VERSION=${ATL_DATABASE_VERSION:-setme}
					ATL_DATABASE_SERVICENAME=mariadb
					ATL_DATABASE_SUPERUSER=${ATL_DATABASE_SUPERUSER:-root}
					ATL_DATABASE_SUPERPASSWORD=${ATL_DATABASE_SUPERPASSWORD:-setme:Please set MySQL "$ATL_DATABASE_SUPERUSER" user"'"s password, by running atl_install_database}
					;;
				*) ATL_DATABASE_PORT=${ATL_DATABASE_PORT:-} ;;
				esac
				if [[ $ATL_DATABASE_TYPE =~ postgresql ]]; then
					# This allows the current user (presumably a maintainer) to access the database with just 'psql'.
					# Update: don't do this, as it causes atl_create to assume a nonexistent db and fail
					#PGDATABASE=$ATL_DATABASE
					:
					# Note we deliberately don't set PGUSER, PGPASSWORD etc, as that would give them a RW connection (maintainers only need RO). Use atl_psql for full accestls
				fi
				case "$ATL_PRODUCT_FULL" in
				jira*) ATL_DATABASE_USE_JNDI=true ;;
				confluence) ATL_DATABASE_USE_JNDI=false ;;
				crowd) ATL_DATABASE_USE_JNDI=true ;;
				bitbucket) ATL_DATABASE_USE_JNDI=true ;;
				esac
			}
			_load_profile_defaults_database "$@"

			_load_profile_defaults_paths() {

				ATL_ROOT=${ATL_ROOT:-}

				case "$ATL_PRODUCT" in
				jira | confluence | crowd | fisheye | crucible)
					ATL_APPDIR_BASE=${ATL_APPDIR_BASE:-$ATL_ROOT/opt/atlassian/${ATL_SHORTNAME}}
					# This used to use the /current/ symlink. But since ATL_APPDIR is frozen into .env/ and might be for an old version, the path must be version-specific
					ATL_APPDIR=${ATL_APPDIR_BASE}/${ATL_VER}
					ATL_DATADIR_BASE=${ATL_DATADIR_BASE:-$ATL_ROOT/var/atlassian/application-data/${ATL_SHORTNAME}}
					ATL_DATADIR_VERSIONED=${ATL_DATADIR_VERSIONED:-true}
					;;
				jethro | invoiceninja)
					ATL_APPDIR_BASE=${ATL_APPDIR_BASE:-$ATL_ROOT/srv/www/${ATL_BASEDOMAIN?}/$ATL_SHORTNAME}
					ATL_APPDIR=${ATL_APPDIR_BASE}/${ATL_VER}
					ATL_DATADIR_BASE=${ATL_DATADIR_BASE:-setme}
					ATL_DATADIR_VERSIONED=${ATL_DATADIR_VERSIONED:-false}
					;;
				postgresql)
					ATL_APPDIR_BASE=/usr/share/postgresql
					ATL_APPDIR=$ATL_APPDIR_BASE/$ATL_DATABASE_VERSION
					ATL_DATADIR_VERSIONED=true
					ATL_DATADIR_BASE=/var/lib/$ATL_DATABASE_TYPE
					;;
				*)
					if [[ ! -v ATL_APPDIR ]]; then {
						_err "Non-standard product '$ATL_PRODUCT' requires ATL_APPDIR to be explicitly set"
						return $?
					}; fi
					if [[ ! -v ATL_DATADIR ]]; then {
						_err "Non-standard product '$ATL_PRODUCT' requires ATL_DATADIR to be explicitly set"
						return $?
					}; fi
					# Don't warn here - our bash prompt command will do it later
					#test -d "$ATL_APPDIR" || echo >&2 "Warning: ATL_APPDIR ($ATL_APPDIR) does not exist"
					#test -d "$ATL_DATADIR" || echo >&2 "Warning: ATL_DATADIR ($ATL_DATADIR) does not exist"
					;;
				esac

				if [[ ${ATL_DATADIR_VERSIONED:-} = true ]]; then
					if [[ ${ATL_MULTITENANT:-} = true ]]; then
						ATL_DATADIR="$ATL_DATADIR_BASE/$ATL_VER/$ATL_TENANT"
						if [[ -v ATL_NEWVER ]]; then
							ATL_DATADIR_NEW="$ATL_DATADIR_BASE/$ATL_NEWVER/$ATL_TENANT"
						else
							# Note, not the current/ symlink, but the actual directory atl_deploy may create
							ATL_DATADIR_NEW="$ATL_DATADIR_BASE/$ATL_VER"
						fi
					else
						# Used to be /current, but this will get frozen into .env/ for old versions
						ATL_DATADIR="${ATL_DATADIR_BASE}/${ATL_VER}"
						if [[ -v ATL_NEWVER ]]; then
							ATL_DATADIR_NEW="${ATL_DATADIR_BASE}/$ATL_NEWVER"
						else
							# Note, not the current/ symlink, but the actual directory atl_deploy may create
							ATL_DATADIR_NEW="$ATL_DATADIR_BASE/$ATL_VER"
						fi
					fi
					ATL_BACKUP_ROOT=${ATL_BACKUP_ROOT:-${ATL_DATADIR_BASE}/backups}
				else
					if [[ ${ATL_MULTITENANT:-} = true ]]; then
						ATL_DATADIR="${ATL_DATADIR_BASE}/$ATL_TENANT"
						ATL_DATADIR_NEW="$ATL_DATADIR"
					else
						ATL_DATADIR="${ATL_DATADIR_BASE}"
						ATL_DATADIR_NEW="$ATL_DATADIR"
					fi
					ATL_BACKUP_ROOT="${ATL_BACKUP_ROOT:-setme:When ATL_DATADIR_VERSIONED=false we can\'t set ATL_BACKUP_ROOT to ATL_DATADIR_BASE/backups, because then backups/ would either be inside the data directory (if ATL_MULTITENANT=false) or be confused for an ATL_TENANT subdirectory. Please pick another location for ATL_BACKUP_ROOT}"
				fi

				case "$ATL_PRODUCT" in
				jira) ATL_DATALOGDIR="${ATL_DATADIR}/log" ;;
				confluence | crowd) ATL_DATALOGDIR="${ATL_DATADIR}/logs" ;;
				jethro) ATL_DATALOGDIR="${ATL_DATADIR}/logs" ;;
				invoiceninja) ATL_DATALOGDIR="${ATL_DATADIR}/storage/logs" ;;
				esac
			}
			_load_profile_defaults_paths "$@"

			case "$ATL_PRODUCT" in
			postgresql)
				ATL_MULTITENANT=true
				if [[ ! -v ATL_VER ]]; then
					ATL_VER="${ATL_DATABASE_VERSION}"
				else
					_err "Please do not set ATL_VER; use ATL_DATABASE_VERSION instead"
					return 1
				fi
				if [[ ! -v ATL_TENANT ]]; then
					ATL_TENANT="$ATL_DATABASE_CLUSTER"
				else
					_err "Please do not set ATL_TENANT; use ATL_DATABASE_CLUSTER instead"
					return 1
				fi
				;;
			esac

			case "$ATL_PRODUCT_FULL" in
			invoiceninja)
				[[ ! -v ATL_USER || $ATL_USER = "www-data" ]] || { echo >&2 "ATL_USER must be 'www-data', not '$ATL_USER'. You can unset it to accept this default"; return 1; }
				[[ ! -v ATL_GROUP || $ATL_GROUP = "www-data" ]] || { echo >&2 "ATL_GROUP must be 'www-data'. You can unset it to accept this default"; return 1; }
				ATL_USER=www-data
				ATL_GROUP=www-data
				;;
			*)
				ATL_USER=${ATL_USER:-$ATL_SHORTNAME}
				[[ -v ATL_GROUP ]] || ATL_GROUP="$(id -gn "$ATL_USER" 2>/dev/null)" || ATL_GROUP="$ATL_SHORTNAME"
				;;
			esac

			ATL_SERVICES_USER=${ATL_SERVICES_USER:-$USER}
			[[ -v ATL_SERVICES_UID ]] || ATL_SERVICES_UID="$(id -u "$ATL_SERVICES_USER" 2>/dev/null)" || ATL_SERVICES_UID="setme:ATL_SERVICES_USER '$ATL_SERVICES_USER' is not defined, so we can't infer UID from that"

			[[ -v ATL_SERVICES_GROUP ]] || ATL_SERVICES_GROUP="$(id -gn "$ATL_SERVICES_USER")" || ATL_SERVICES_GROUP=adm # If unset, use the primary group of ATL_SERVICES_USER if it exists, or 'adm' otherwise
			[[ -v ATL_SERVICES_GID ]] || ATL_SERVICES_GID="$(id -g "$ATL_SERVICES_GROUP" 2>/dev/null)" || ATL_SERVICES_GID=setme

			# For multitenant, ATL_FQDN will have 1 more component than ATL_APPDOMAIN
			ATL_APPDOMAIN="${ATL_APPDOMAIN:-$ATL_LONGNAME}"                 # E.g. 'easyjethro.com.au'
			ATL_FQDN=${ATL_FQDN:-${ATL_TENANT:+$ATL_TENANT.}$ATL_APPDOMAIN} # E.g. 'admin.easyjethro.com.au'

			# Could we infer ATL_BASEDOMAIN from ATL_FQDN? Probably, if we knew valid TLDs then we could match .*(.+\.$tld)
			# For now this variable is unused anywhere except email2jira - define it manually in profiles that use that.
			#ATL_BASEDOMAIN=

			# But bash sucks too much to bother - just force users to set it manually
			ATL_BASEURL=${ATL_BASEURL:-https://$ATL_FQDN${ATL_URLPREFIX:+/$ATL_URLPREFIX}}
			if [[ ! -v ATL_ORGANIZATION ]]; then
				# Figure out the orgname from the FQDN, but finding the rightmost part >3 chars wide (ignoring 'com', 'org', 'au', 'uk' etc)
				local tmp="$ATL_FQDN"
				local lastbit="${tmp##*.}"
				while [[ ${#lastbit} -le 3 && $tmp =~ \. ]]; do
					#log "Discarding $lastbit"
					tmp="${tmp%.*}"
					lastbit="${tmp##*.}"
				done
				#log "Using '$lastbit' from FQDN as ATL_ORGANIZATION"
				ATL_ORGANIZATION="$lastbit"
			fi

			ATL_PROFILE_REPO=${ATL_PROFILE_REPO:-"http://localhost:8610/$ATL_ORGANIZATION/atlassian_app_profiles"}
			# Where the monitoring system sends alerts. See monitoring/templates/atlassian.nagios.cfg
			ATL_MONITORING_NOTIFICATION_EMAIL=${ATL_MONITORING_NOTIFICATION_EMAIL:-$ATL_ORGANIZATION@monitoring.redradishtech.com}

			# This used to be called ATL_HOSTNAME_INTERNAL, which was a misnomer
			# It may be overridden when a SSH port-forward goes to a local interface e.g. jira.example.com.test
			ATL_FQDN_INTERNAL=${ATL_FQDN_INTERNAL:-${ATL_SHORTNAME//_/-}.internal}
			# ATL_BASEURL_INTERNAL is the HTTP (not AJP) internal URL our app is available on.
			# For Tomcat apps, http://$ATL_FQDN_INTERNAL:80 is passed the scheme/port/host of the frontend URL, and is intended to be proxied,
			# whereas http://$ATL_FQDN_INTERNAL:8080 (or 8090 for Confluence) doesn't, and will work better with direct access.
			case "$ATL_PRODUCT" in
			jira) ATL_BASEURL_INTERNAL="${ATL_BASEURL_INTERNAL:-http://${ATL_FQDN_INTERNAL}:8080${ATL_URLPREFIX:-}}" ;;
			confluence) ATL_BASEURL_INTERNAL="${ATL_BASEURL_INTERNAL:-http://${ATL_FQDN_INTERNAL}:8090${ATL_URLPREFIX:-}}" ;;
			jethro) ATL_BASEURL_INTERNAL="http://${ATL_FQDN_INTERNAL}${ATL_URLPREFIX:-}" ;; # Sadly Jethro hardcodes https, so some responses might have bad urls returned
			*) _err "ATL_BASEURL_INTERNAL not set for $ATL_PRODUCT" ;;
			esac

			# Set default blank to prevent the script breaking..
			ATL_SYSTEMD_DEPENDENCIES=
			# If our database is local, figure out the systemd service which we depend on.
			if [[ -z ${ATL_SYSTEMD_DEPENDENCIES:-} && $ATL_DATABASE_HOST = localhost ]]; then
				if [[ $ATL_DATABASE_TYPE = postgresql ]]; then
					# If Postgres, assume the service name will be 'postgresql-9.5-main' or similar
					# grep -P enables perl syntax, which is necessary for the non-greedy patch
					#dbservice=$(systemctl list-units  -t service --state loaded "$ATL_DATABASE_TYPE*" | grep -P -o "$ATL_DATABASE_TYPE@.*?-main.service")
					# Should we use state 'loaded' or 'active'?
					# A long-lived installation might have e.g. postgresql@9.6-main and postgresql@11-main. Only 11 will be running.
					# If we used 'loaded' then both services would be added as dependencies here, which is wrong
					# If we use 'active' then only the running instance (11) is used, but we run the risk of not adding anything if 11 happens to be offline for some reason.
					# Too few deps is less of a risk than too many, so let's go with 'active'.
					dbservice=$(systemctl list-units -t service --state active "$ATL_DATABASE_SERVICENAME@${ATL_DATABASE_VERSION}-${ATL_DATABASE_CLUSTER}.service" | grep -P -o "$ATL_DATABASE_SERVICENAME@.*?-${ATL_DATABASE_CLUSTER}.service")
				else
					# If MySQL or something else, assume there's just one database service
					dbservice=$(systemctl list-units -t service --state loaded | grep -o "$ATL_DATABASE_SERVICENAME.service")
				fi
				if [[ -n $dbservice ]]; then
					# shellcheck disable=SC2116
					ATL_SYSTEMD_DEPENDENCIES="$(echo "$dbservice")" # Convert newline-separated into space-separated
				else
					warn "Couldn't figure out what database our systemd service uses. This is not critical"
					# Set to nothing so the service template expands to 'Requires=', which is fine
					ATL_SYSTEMD_DEPENDENCIES=
				fi
			fi

			# Where to pg_dump backups to, before moving to their final destination below $ATL_BACKUP_ROOT. This should be on a filesystem with sufficient space for a database dump, and ideally the same filesystem as ATL_BACKUP_ROOT so the final mv is fast
			ATL_BACKUP_TMP=${ATL_BACKUP_TMP:-$(readlink -m "${ATL_BACKUP_ROOT}/../tmp")}
			if [[ $ATL_BACKUP_TMP != "$ATL_DATADIR_BASE/tmp" && ! -d "$ATL_BACKUP_TMP" ]]; then
				warn "ATL_BACKUP_TMP has been migrated from $ATL_DATADIR_BASE/tmp to $ATL_BACKUP_TMP"
			fi
			# We might want to set ATL_BACKUP_TYPES to BLANK (=no backups), in which case we don't want the default value; hence the -v check
			if [[ ! -v ATL_BACKUP_TYPES ]]; then
				# This variable must be set appropriately even on servers that don't make rsnapshot backups, like sandboxes. The activation script must check other vars (like ATL_ROLE) to determine if a backup is actually made on the current server. This is because $ATL_MANAGE/backupmirror/sync_backup relies on this variable to sync backups
				ATL_BACKUP_TYPES=rsnapshot
			fi
			ATL_BACKUP_DATABASEDUMP=${ATL_BACKUP_ROOT}/latest-database-dump
			ATL_BACKUP_TARSNAP_USER=${ATL_BACKUP_TARSNAP_USER:-admin@redradishtech.com}
			ATL_BACKUP_TARSNAP_CACHEDIR="/var/cache/tarsnap/${ATL_ORGANIZATION}"
			ATL_BACKUP_TARSNAP_KEYFILE="/etc/tarsnap-${ATL_ORGANIZATION}-${HOSTNAME}.key"
			# Back up every 4 hours. This is incorporated into a */<number> cron expression.
			ATL_BACKUP_HOURLY_FREQUENCY=${ATL_BACKUP_HOURLY_FREQUENCY:-4}

			# The Context path e.g. '' (default), '/jira' or '/jira7'
			ATL_URLPREFIX=${ATL_URLPREFIX:-}

			# Generate a probably-unique shutdown port based on $ATL_LONGNAME
			# Note: we avoid '0' as it turns the number into octal
			ATL_SHUTDOWNPORT=${ATL_SHUTDOWNPORT:-$((8000 + $(echo "$ATL_LONGNAME" | md5sum | sed -e 's/[^1-9]//g' | cut -c 1-5) % 2000))}
			# apache2, nginx, nginx-elb
			# By default, warn on any mails in the queue, or any recent mail bounces.

			# Update: we don't set defaults for the SSL cert, because we don't know what a reasonable default might be (unlike say ATL_WEBSERVER). In the case of CERTCHAINFILE we might well want it unset, and currently we can't distinguish between unset and null
			# Default to LetsEncrypt.
			#ATL_SSLCERTFILE=${ATL_ROOT}${ATL_SSLCERTFILE:-/etc/letsencrypt/live/${ATL_LONGNAME}/cert.pem}
			#ATL_SSLCERTKEYFILE=${ATL_ROOT}${ATL_SSLCERTKEYFILE:-/etc/letsencrypt/live/${ATL_LONGNAME}/privkey.pem}
			#ATL_SSLCERTCHAINFILE=${ATL_ROOT}${ATL_SSLCERTCHAINFILE:-/etc/letsencrypt/live/${ATL_LONGNAME}/chain.pem}
			# We can default these to blank since they often aren't needed
			# Update 23/Apr/22: no we can't blank them or we lose the values set in foo.company.com. But we do not non-null values set otherwise apache2.conf tokens fail to replace
			ATL_SSLCERTCAFILE=${ATL_SSLCERTCAFILE:-}
			ATL_SSLCERTCHAINFILE=${ATL_SSLCERTCHAINFILE:-}
			ATL_SSLCACERTIFICATEFILE=${ATL_SSLCACERTIFICATEFILE:-}

			case ${ATL_PRODUCT} in
			crowd) ATL_TOMCAT_SUBDIR=apache-tomcat/ ;;
			*) ATL_TOMCAT_SUBDIR="" ;;
			esac

			ATL_LOGDIR=${ATL_LOGDIR:-${ATL_APPDIR}/${ATL_TOMCAT_SUBDIR}logs}   # Where scripts should write their logs to
			ATL_LOCKDIR=${ATL_LOCKDIR:-${ATL_APPDIR}/${ATL_TOMCAT_SUBDIR}temp} # Where scripts should store app-local lockfiles
			ATL_LOCKDIR_GLOBAL="${ATL_ROOT:-}/var/lock/atl_manage"	# Where scripts store server-wide lockfiles coordinating across multiple apps
			ATL_BINDIR="${ATL_BINDIR:-${ATL_APPDIR}/bin}"

			ATL_PATCHQUEUE_REPO=${ATL_PATCHQUEUE_REPO:-http://localhost:8610/$ATL_ORGANIZATION/app_patchqueue}
			ATL_PATCHQUEUE_REPO_GENERIC=/home/jturner/src/redradishtech/atl_app_patchqueue_everyone

			# Regex of ATL_* variables whose contents should not be visible to $ATL_USER.
			# A regex is not ideal as users can't easily append to it. It's a pity bash doesn't export arrays
			# These secret vars stored in $ATL_APPDIR/.env/ATL_... by 'atl_freeze' will only be readable by root.
			# Note that ATL_DATABASE_PASSWORD is not included, since $ATL_USER knows its contents (and nagios/userdirectories.healthcheck needs it
			# Sensitive vars are ones only root should see, not ATL_USER or ATL_SERVICES_USER. Given our restrictive 027 umask, $ATL_APPDIR/.env vars are not visible to $ATL_USER normally, so being in ATL_SENSITIVE_VARS hides mostly from $ATL_SERVICES_USER.
			# The .* in ATL_.*DATABASE_SUPERPASSWORD is to catch ATL_MYSQL_DATABASE_SUPERPASSWORD, etc, intermediate variables
			# The ATL_.*_API_TOKEN covers ATL_CLOUDFLARE_API_TOKEN and ATL_JIRA_API_TOKEN.
			# The ATL_.*_API_KEY covers ATL_MAILCHIMP_API_KEY and ATL_5CENTSMS_API_KEY
			# The ATL_(?!DATABASE_).*PASSWORD at the end is a catch-all for all ATL.*PASSWORD variants except ATL_DATABASE_PASSWORD. It must be at the end, otherwise ATL_DATABASE_SUPERPASSWORD isn't considered sensitive
			ATL_SENSITIVE_VARS='(ATL_USERNAME|ATL_PASSWORD|ATL_.*DATABASE_SUPERPASSWORD|ATL_ISSO_SMTP_PASSWORD|ATL_ISSO_ADMINPASSWORD|ATL_EMAIL_TESTACCOUNT_OAUTH_.*|ATL_SSLCERTKEY|ATL_.*_API_TOKEN|ATL_.*_API_KEY|ATL_SMTP_PASSWORD|ATL_(?!DATABASE_).*PASSWORD)'

			if [[ -v ATL_REPLICATION_PRIMARY || -v ATL_REPLICATION_STANDBY ]]; then
				ATL_REPLICATION_TYPE="${ATL_REPLICATION_TYPE:-lsyncd}"
				# Frequency of replication filesystem sync, in minutes. see $ATL_APPDIR/replication/replication.cron
				ATL_REPLICATION_FREQUENCY=${ATL_REPLICATION_FREQUENCY:-60}
				ATL_REPLICATION_PRIMARY_SYNCUSER=${ATL_REPLICATION_PRIMARY_SYNCUSER:-$USER}
				# Set this to a sudo'd account on servers that have ssh 'PermitRootLogin no'
				ATL_REPLICATION_STANDBY_SYNCUSER=${ATL_REPLICATION_STANDBY_SYNCUSER:-$ATL_USER}
				ATL_REPLICATION_PRIMARY_DATADIR_BASE=${ATL_REPLICATION_PRIMARY_DATADIR_BASE:-$ATL_DATADIR_BASE}
				ATL_REPLICATION_STANDBY_DATADIR_BASE=${ATL_REPLICATION_STANDBY_DATADIR_BASE:-$ATL_DATADIR_BASE}
				# Backup mirroring is kicked off from the source (/etc/cron.d/$ATL_SHORTNAME-replication derived from $ATL_APPDIR/backups/replication.healthcheck), and its $ATL_MANAGE/replication/remoterun script needs to know the mirror's APPDIR_BASE to find the right .env to source. This can be overridden e.g. to ATL_REPLICATION_STANDBY_APPDIR_BASE=/opt/atlassian/confluence-test
				ATL_REPLICATION_PRIMARY_APPDIR_BASE=${ATL_REPLICATION_PRIMARY_APPDIR_BASE:-$ATL_APPDIR_BASE}
				ATL_REPLICATION_STANDBY_APPDIR_BASE=${ATL_REPLICATION_STANDBY_APPDIR_BASE:-$ATL_APPDIR_BASE}

				case "$ATL_PRODUCT" in
				# Jira shouldn't replicate the index files, as it leads to replication 'failures' when index files disappear.
				# Also don't replicate data/attachments/**/
				jira) ATL_REPLICATION_RSYNC_EXCLUDES='--exclude "caches/indexes**" --exclude "**/thumbs/' ;;
				esac

				if [[ -v ATL_REPLICATION_PRIMARY ]]; then
					ATL_REPLICATION_SYNCUSER="${ATL_REPLICATION_PRIMARY_SYNCUSER:-setme}" # Used in backups/replication.healthcheck to refer to 'the SYNCUSER of wherever we're installed'

					# If we're the replication source, we know our own hostname, which is embedded in the SSH public key generated by events/install-post/backups-archive
					ATL_REPLICATION_PRIMARY_HOST=${ATL_REPLICATION_PRIMARY_HOST:-$HOSTNAME}
					ATL_REPLICATION_PRIMARY_HOST_UNAME=${ATL_REPLICATION_PRIMARY_HOST_UNAME:-$ATL_REPLICATION_PRIMARY_HOST}
					ATL_REPLICATION_STANDBY_HOST=${ATL_REPLICATION_STANDBY_HOST:-setme:Set to replication destination host. No suggestion.}
					ATL_REPLICATION_STANDBY_HOST_UNAME=${ATL_REPLICATION_STANDBY_HOST_UNAME:-$ATL_REPLICATION_STANDBY_HOST}
					# Used by replication/sync in --usermap
					ATL_REPLICATION_STANDBY_USER=${ATL_REPLICATION_STANDBY_USER:-$ATL_USER}
					# Used by replication/sync in --groupmap
					ATL_REPLICATION_STANDBY_GROUP=${ATL_REPLICATION_STANDBY_GROUP:-$ATL_GROUP}

				elif [[ -v ATL_REPLICATION_STANDBY ]]; then

					ATL_REPLICATION_SYNCUSER="${ATL_REPLICATION_STANDBY_SYNCUSER:-setme}" # Used in backups/replication.healthcheck to refer to 'the SYNCUSER of wherever we're installed'

					ATL_REPLICATION_PRIMARY_HOST=${ATL_REPLICATION_PRIMARY_HOST:-setme:Set to replication primary host. No suggestion.}
					ATL_REPLICATION_PRIMARY_HOST_UNAME=${ATL_REPLICATION_PRIMARY_HOST_UNAME:-$ATL_REPLICATION_PRIMARY_HOST}
					# Used by old rsync-style replication/sync in --usermap
					ATL_REPLICATION_PRIMARY_USER=${ATL_REPLICATION_PRIMARY_USER:-$ATL_USER}
					# Used by old rsync-style replication/sync in --groupmap
					ATL_REPLICATION_PRIMARY_GROUP=${ATL_REPLICATION_PRIMARY_GROUP:-$ATL_GROUP}
					ATL_REPLICATION_STANDBY_HOST=${ATL_REPLICATION_STANDBY_HOST:-$HOSTNAME}
					ATL_REPLICATION_STANDBY_HOST_UNAME=${ATL_REPLICATION_STANDBY_HOST_UNAME:-$ATL_REPLICATION_STANDBY_HOST}

					if [[ $ATL_ROLE =~ prod ]]; then
						_err "Unexpected situation: ATL_ROLE is prod ($ATL_ROLE) but we are also marked as a replication destination (ATL_REPLICATION_STANDBY). The production app is normally ATL_REPLICATION_PRIMARY, not STANDBY, so this is likely an error in  $ATL_PROFILEDIR"
					fi

				fi
			fi

			if [[ -v ATL_BACKUPMIRROR_SOURCE || -v ATL_BACKUPMIRROR_DESTINATION ]]; then

				if [[ -v ATL_BACKUPMIRROR_SOURCE ]]; then
					# Backup mirroring must be done as 'root' or a root-equivalent sudo account on the source, because backups are only root-accessible.
					ATL_BACKUPMIRROR_SOURCE_SYNCUSER=${ATL_BACKUPMIRROR_SOURCE_SYNCUSER:-$USER}
					# Set this to a sudo'd account on servers that have ssh 'PermitRootLogin no'
					ATL_BACKUPMIRROR_DESTINATION_SYNCUSER=${ATL_BACKUPMIRROR_DESTINATION_SYNCUSER:-setme:SSH to the backupmirror server as this account. Suggested value: ${ATL_USER}-sandbox}
					ATL_BACKUPMIRROR_SYNCUSER="${ATL_BACKUPMIRROR_SOURCE_SYNCUSER}" # Used in backups/backupmirror.healthcheck to refer to 'the SYNCUSER of wherever we're installed'
					# Backup mirroring is kicked off from the source (/etc/cron.d/$ATL_SHORTNAME-backupmirror derived from $ATL_APPDIR/backups/backupmirror.healthcheck), and its $ATL_MANAGE/backupmirror/remoterun script needs to know the mirror's APPDIR_BASE to find the right .env to source. This can be overridden e.g. to ATL_BACKUPMIRROR_DESTINATION_APPDIR_BASE=/opt/atlassian/confluence-test
					ATL_BACKUPMIRROR_DESTINATION_APPDIR_BASE=${ATL_BACKUPMIRROR_DESTINATION_APPDIR_BASE:-setme:Set to the appdir of instance storing the backupmirror. Suggested: ${ATL_APPDIR_BASE}-sandbox} # Assume we're storing 'jira' backupmirror on 'jira-sandbox'
					# If we're the backupmirror source, we know our own hostname, which is embedded in the SSH public key generated by events/install-post/backups-archive
					ATL_BACKUPMIRROR_SOURCE_HOST=${ATL_BACKUPMIRROR_SOURCE_HOST:-$HOSTNAME}
					ATL_BACKUPMIRROR_SOURCE_HOST_UNAME=${ATL_BACKUPMIRROR_SOURCE_HOST_UNAME:-$ATL_BACKUPMIRROR_SOURCE_HOST}
					ATL_BACKUPMIRROR_DESTINATION_HOST=${ATL_BACKUPMIRROR_DESTINATION_HOST:-setme:Set to backupmirror destination host. No suggestion.}
					ATL_BACKUPMIRROR_DESTINATION_HOST_UNAME=${ATL_BACKUPMIRROR_DESTINATION_HOST_UNAME:-$ATL_BACKUPMIRROR_DESTINATION_HOST}
				elif [[ -v ATL_BACKUPMIRROR_DESTINATION ]]; then

					ATL_BACKUPMIRROR_SOURCE_SYNCUSER=${ATL_BACKUPMIRROR_SOURCE_SYNCUSER:-setme:SSH to the backupmirror server as this account. Suggested value (as backups are only root-accessible): root}
					ATL_BACKUPMIRROR_DESTINATION_SYNCUSER=${ATL_BACKUPMIRROR_DESTINATION_SYNCUSER:-${ATL_USER}}
					ATL_BACKUPMIRROR_SYNCUSER="${ATL_BACKUPMIRROR_DESTINATION_SYNCUSER:-setme}" # Used in backups/backupmirror.healthcheck to refer to 'the SYNCUSER of wherever we're installed'
					# On dev/sandbox servers we often want a periodically synced backup from production. This directory is where it would be stored by bin/atl_backupmirror_fetch:
					ATL_BACKUPMIRROR_DESTINATION_BACKUP_ROOT="${ATL_BACKUPMIRROR_DESTINATION_BACKUP_ROOT:-$ATL_DATADIR_BASE/backups-from-production}"
					if [[ -v ATL_BACKUPMIRROR_ROOT ]]; then { echo >&2 "Please replace ATL_BACKUPMIRROR_ROOT with ATL_BACKUPMIRROR_DESTINATION_BACKUP_ROOT"; return 1; }; fi
					#The mirror destination does the actual rsync pull, so needs to know where (on the source) the backup root is
					ATL_BACKUPMIRROR_SOURCE_BACKUP_ROOT=${ATL_BACKUPMIRROR_SOURCE_BACKUP_ROOT:-setme:Where (on the source) the backup root is. Suggested value: ${ATL_BACKUP_ROOT/-sandbox/}} # Assume that we're on e.g. jira-sandbox, acting as a backupmirror for jira
					# The atl_backupmirror_restore script needs to know the primary's database name.
					ATL_BACKUPMIRROR_SOURCE_DATABASE=${ATL_BACKUPMIRROR_SOURCE_DATABASE:-setme:Database name of source instance. Suggested: ${ATL_DATABASE/-sandbox/}} # E.g. jira-sandbox backing up jira database
					# atl_backupmirror_restore may need to map file ownership from $ATL_BACKUPMIRROR_SOURCE_UID to $ATL_UID
					# Note: we use the uid instead of username because the backupmirror source user may not exist on the destination, but the uid will be in the files
					ATL_BACKUPMIRROR_SOURCE_UID=${ATL_BACKUPMIRROR_SOURCE_UID:-setme:UID of files on the source. No suggestion}
					ATL_BACKUPMIRROR_SOURCE_GID=${ATL_BACKUPMIRROR_SOURCE_GID:-setme:GID of files on the source. No suggestion}
					ATL_BACKUPMIRROR_SOURCE_HOST=${ATL_BACKUPMIRROR_SOURCE_HOST:-setme:Set to backupmirror source host. No suggestion.}
					ATL_BACKUPMIRROR_SOURCE_HOST_UNAME=${ATL_BACKUPMIRROR_SOURCE_HOST_UNAME:-$ATL_BACKUPMIRROR_SOURCE_HOST}
					# If we're not production, and dbconfig.xml is identical on source/dest, let atl_backupmirror_restore save space by hardlinking the home dir to backupmirror
					if [[ -v ATL_ZFS ]]; then
						ATL_BACKUPMIRROR_HARDLINK=${ATL_BACKUPMIRROR_HARDLINK:-false}
					else
						ATL_BACKUPMIRROR_HARDLINK=${ATL_BACKUPMIRROR_HARDLINK:-true}
					fi
					# The ATL_DATADIR on the backupmirror source. We default it to $ATL_DATADIR, but if we're doing a backupmirror from 'jira' on prod to 'jira-sandbox' on sandbox, then this needs to be explicitly set (to '/var/atlassian/application-data/jira/current' in our example)
					# Used in $ATL_MANAGE/backupmirror/sync_backup to sync Jira/Confluence indexes along with the last rsnapshot, to form a fully restorable backup.
					ATL_BACKUPMIRROR_SOURCE_DATADIR=${ATL_BACKUPMIRROR_SOURCE_DATADIR:-setme:Datadir path on the source. Suggested: ${ATL_DATADIR/-sandbox/}}

					if [[ $ATL_ROLE =~ prod ]]; then
						_err "Unexpected situation: ATL_ROLE is prod ($ATL_ROLE) but we are also marked as a backup mirror destination (ATL_BACKUPMIRROR_DESTINATION). The production app is normally ATL_BACKUPMIRROR_SOURCE, not DESTINATION, so this is likely an error in  $ATL_PROFILEDIR"
					fi

				fi
			fi

			#
			## LetsEncrypt
			# LE email for 'urgent renewal and security notices'. If blank, will be prompted for when LE is first run
			#ATL_LETSENCRYPT_EMAIL=

			# Cloudflare
			# This is in the wrong place
			if [[ -v ATL_CLOUDFLARE_API_TOKEN ]]; then
				if [[ -v ATL_SSLCERT_VIA_CLOUDFLARE ]]; then
					echo >&2 "ATL_SSLCERT_VIA_CLOUDFLARE is set"
					local cfcert="$ATL_APPDIR/cloudflare/cloudflare_origin_cert/cert.pem"
					local cfkey="$ATL_APPDIR/cloudflare/cloudflare_origin_cert/privkey.pem"
					[[ ! -v ATL_SSLCERTFILE ]] || { echo >&2 "Please do not set ATL_SSLCERTFILE. It will be automatically set to $cfcert (because ATL_CLOUDFLARE_API_TOKEN is set)"; return 1; }
					ATL_SSLCERTFILE="$cfcert"
					[[ ! -v ATL_SSLCERTKEYFILE ]] || { echo >&2 "Please do not set ATL_SSLCERTKEYFILE. It will be automatically set to $cfkey (because ATL_CLOUDFLARE_API_TOKEN is set)"; return 1; }
					ATL_SSLCERTKEYFILE="$cfkey"
				elif [[ -v ATL_SSLCERT_VIA_LETSENCRYPT ]]; then
					echo >&2 "Using LetsEncrypt DNS-01 challenge"
				else
					_err "ATL_CLOUDFLARE_API_TOKEN is set, but its purpose is unknown. Please set ATL_SSLCERT_VIA_CLOUDFLARE if $ATL_LONGNAME is fronted by Cloudflare DNS, or ATL_SSLCERT_VIA_LETSENCRYPT if the API token is used by LetsEncrypt's DNS-01 challenge type"
				fi
			fi

			# Set ATL_DATADIR_LASTSYNCED to the last syncoid run. This variable can then be used in ATL_BANNERTEXT in $ATL_PROFILEDIR/${ATL_SHORTNAME}-post
			# Disabled Nov/23: this takes 100ms and isn't even used AFAIK.
			#shellcheck disable=SC2031
			#if [[ -v ATL_ZFS ]]; then
			#	if [[ -d $ATL_DATADIR_BASE/$ATL_VER ]]; then
			#		ATL_DATADIR_LASTSYNCED=$(zfs get -Hd 1 -t snapshot creation "${ATL_ZFSPOOL}$ATL_DATADIR_BASE/$ATL_VER" | grep syncoid | awk -F'\t' '{print $3}');
			#	fi
			#fi

			# Default -Xmx settings
			if [[ ! -v ATL_MAXMEM ]]; then
				case "$ATL_PRODUCT" in
				crowd) ATL_MAXMEM="512m" ;;
				*) ATL_MAXMEM="2048m" ;;
				esac
			fi

			# Sample email2jira config:
			#ATL_EMAIL_INCOMING_USERNAME=jira@example.com
			#ATL_EMAIL_INCOMING_PASSWORD=...
			#ATL_EMAIL_TESTACCOUNT_OAUTH_ACCESS_TOKEN=...
			#ATL_EMAIL_TESTACCOUNT_OAUTH_TOKEN_SECRET=...
			#ATL_EMAIL_TESTISSUE=TESTEMAIL-1
			#ATL_EMAIL_TESTACCOUNT_OAUTH_CERT=
			#ATL_EMAIL_TESTACCOUNT_OAUTH_PRIVKEY=...
			# Reduce idle to 5m because we keep getting 're-poll failed' errors
			# ATL_EMAIL_INCOMING_IDLESECS=360
			# for the email2jira patch, this configures how long fetchmail waits before re-polling. Normally IDLE means we don't need rapid re-polls, but sometimes IDLE breaks
			ATL_EMAIL_INCOMING_IDLESECS=${ATL_EMAIL_INCOMING_IDLESECS:-3600}

			# Useful for commands like atl_stop which need to know how the app works
			case "$ATL_PRODUCT" in
				jira)
					if version_lessequalthan "$ATL_VER" 7.11.0; then
						ATL_PRODUCT_RUNTIME_TECHNOLOGY=java-azul-8
					elif version_lessthan "$ATL_VER" "9.5"; then
						ATL_PRODUCT_RUNTIME_TECHNOLOGY=java-openjdk-11
					else
						ATL_PRODUCT_RUNTIME_TECHNOLOGY=java-openjdk-17
					fi
					;;
				confluence)
					if version_lessequalthan "$ATL_VER" 6.10.2; then
						ATL_PRODUCT_RUNTIME_TECHNOLOGY=java-azul-8
					elif version_lessequalthan "$ATL_VER" 8.0; then
						ATL_PRODUCT_RUNTIME_TECHNOLOGY=java-openjdk-11
					else
						ATL_PRODUCT_RUNTIME_TECHNOLOGY=java-openjdk-17
					fi
					;;
				fisheye)
					ATL_PRODUCT_RUNTIME_TECHNOLOGY=java-azul-8
					;;
				invoiceninja) ATL_PRODUCT_RUNTIME_TECHNOLOGY=php7.4-fpm ;;
				jethro) ATL_PRODUCT_RUNTIME_TECHNOLOGY="${ATL_PRODUCT_RUNTIME_TECHNOLOGY:-php8.4-fpm}" ;;
				#jethro) ATL_PRODUCT_RUNTIME_TECHNOLOGY="${ATL_PRODUCT_RUNTIME_TECHNOLOGY:-php7.4-fpm}" ;;
				website) ATL_PRODUCT_RUNTIME_TECHNOLOGY=$ATL_WEBSERVER ;;
				postgresql) ATL_PRODUCT_RUNTIME_TECHNOLOGY=postgresql ;;
				*) ATL_PRODUCT_RUNTIME_TECHNOLOGY="setme:'$ATL_PRODUCT' is invalid" ;;
			esac

			# Does our app have a persistent runtime, like a JVM? If so set the systemd service name in ATL_SYSTEMD_SERVICENAME.
			case "$ATL_PRODUCT_RUNTIME_TECHNOLOGY" in
			java*)
				ATL_SYSTEMD_SERVICENAME=${ATL_SYSTEMD_SERVICENAME:-${ATL_SHORTNAME}}
				;;
			php*)
				# Assume we reuse phpX-Y-fpm with a custom pool
				ATL_SYSTEMD_SERVICENAME=${ATL_SYSTEMD_SERVICENAME:-${ATL_PRODUCT_RUNTIME_TECHNOLOGY}}
				ATL_SERVICE_INSTALLED_EXTERNALLY=true
				;;
			postgresql)
				ATL_SYSTEMD_SERVICENAME=postgresql-${ATL_DATABASE_VERSION}-${ATL_DATABASE_CLUSTER}.service
				ATL_SERVICE_INSTALLED_EXTERNALLY=true
				;;
			esac
			ATL_SERVICENAME="${ATL_SYSTEMD_SERVICENAME}" # For backwards-compat, e.g. old patchqueue's

			# Keep these in sync with $ATL_MANAGE/lib/atl_env
			export JLOGDIR="$ATL_LOGDIR"
			export JLOCKDIR="$ATL_LOCKDIR"
			export JLOCKDIR_GLOBAL="$ATL_LOCKDIR_GLOBAL"

			if [[ ! $ATL_ROLE =~ ^(prod|standby)$ ]]; then
				# Set ATL_NOEMAIL on non-prod, non-standby hosts
				case "${ATL_NOEMAIL:-}" in
				setme)
					# We pre-set ATL_NOEMAIL=setme, and then a profile may unset it or set it to 'true'
					ATL_NOEMAIL=true
					;;
				true | '') : ;;
				*) _err "ATL_NOEMAIL must be either 'true' or unset, not '$ATL_NOEMAIL" ;;
				esac
				# We only insist on monitoring in production.
				ATL_MONITORING_REQUIRED=${ATL_MONITORING_REQUIRED:-false}
			fi
			# ATL_PRODUCT_CAPITALIZED is used in $ATL_MANAGE/lib/report_copytoclient, and in .hg/patches/hikari_connectionpool
			case "$ATL_PRODUCT_FULL" in
			jira*) ATL_PRODUCT_CAPITALIZED="Jira" ;;
			confluence) ATL_PRODUCT_CAPITALIZED="Confluence" ;;
			crowd) ATL_PRODUCT_CAPITALIZED="Crowd" ;;
			bitbucket) ATL_PRODUCT_CAPITALIZED="BitBucket" ;;
			*) ATL_PRODUCT_CAPITALIZED="${ATL_PRODUCT^}" ;;
			esac

			# Used in events/upgrade-running-pre/atl
			ATL_PLUGINDATA_JSON="$ATL_PROFILEDIR/plugindata/$ATL_LONGNAME/$ATL_VER.json"
			ATL_PROFILE_SHLVL=$SHLVL

			if [[ -v ATL_ZFS ]]; then
				#local dbfs="${ATL_ZFSPOOL}/var/lib/postgresql/$ATL_DATABASE_VERSION"
				[[ -v ATL_ZFSPOOL ]] || _err "Please set ATL_ZFSPOOL"
				local dbfs="${ATL_ZFSPOOL}/var/lib/postgresql"
				(
					#shellcheck source=/opt/atl_manage/lib/zfs.sh
					. "$ATL_MANAGE"/lib/zfs.sh
					zfs_filesystem_exists "$dbfs" || _err "Expected to find ZFS filesystem $dbfs"
				)
			else
				if [[ -v ATL_ZFSPOOL ]]; then
					_err "Please set ATL_ZFS=true"
				fi
			fi

			# Put $ATL_APPDIR/bin first in the path so it takes precedence over ATL_MANAGE/bin (e.g. for 'atl help')
			# Note: this causes problems because PATH accumulates on each 'atl load'. So e.g. atl_sql from the previously
			# loaded app will take precedence to $ATL_MANAGE/bin/atl_sql
			# 20/Apr/23: ameliorate the above problem by also putting ATL_MANAGE/bin in the path each time :/
			#export PATH="$ATL_APPDIR/bin:$ATL_MANAGE/bin:$PATH"
			# 2/May/23: reinstate setting PATH, since it's really useful for EJ and there is no other logical place to do it.
			# Fix above problems by stripping just this entry from $PATH in atl_unload
			. "$ATL_MANAGE/lib/loadfuncs.sh" "$ATL_APPDIR/.env"
			if [[ -d "$ATL_BINDIR" ]]; then
				. "$ATL_MANAGE/lib/loadfuncs.sh" "$ATL_BINDIR"
				export PATH="$ATL_BINDIR:$PATH"
			fi
		}

		load_global_defaults "$@"
		if [[ $1 != global ]]; then
			load_profile_defaults "$@"
		fi
	}

	# Run a command in the background, storing its output in a temporary file for later orderly retrieval (in lib/prompt.sh).
	# Using an intermediate file  avoids the problem of a backgrounded process suddenly writing to stdout and visually corrupting the prompt
	# Used at the end of lib/profile.sh
	run_in_background() {
		(
			flock -x 200
			exec 0<&- # Close stdin, although I don't think anything could try to write to it
			"$@" >>"$(cachedir --)/backgrounded_on_profile_load_output"
		) 200>"$(cachedir --)/backgrounded_on_profile_load_output.lock" &
		disown
		#& disown
		# The 'disown' prevents an ugly '[1]-  Done                    ( atl_check_appdeployment || : )' in the terminal
	}

	atl_role_specific_tweaks() {
		if [[ $ATL_ROLE = prod ]]; then
			alias rm='rm -i'
		fi
	}

	_atl_load_help() {
		echo -e "\n${RED}$*${RESET}\n"
		echo >&2 "Purpose: Contextualize your shell for the app currently being worked on."
		echo >&2 "Usage:"
		echo >&2 "	atl_load <profilename_or_partname>		# Load a profile"
		echo >&2 "	atl load <profilename_or_partname>		# Load a profile"
		echo >&2 "	atl profile load global					# Source profile-independent vars"
		echo >&2 "See also:"
		echo >&2 "	atl <list|ls>							# List available profiles"
		echo >&2 "	atl unload 								# Unload profile"
		echo >&2 "	atl freeze								# Save loaded profile vars to \$ATL_APPDIR/.env"
		echo >&2
		echo >&2 "Multi-tenant apps:"
		echo >&2
		echo >&2 "  Some apps are multi-tenant, i.e a single codebase runs but connects to a different ATL_DATABASE per 'tenant'."
		echo >&2 "  Only the caller (of atl_profile) knows the tenant's ATL_DATABASE value, unlike the usual case where ATL_DATABASE is read from profile files."
		echo >&2 "  To accommodate this, write a custom $ATL_APPDIR/bin/atl_load that pre-sets ATL_DATABASE, before calling _atl_profile with the --preserve flag:"
		echo >&2
		echo >&2 "	ATL_TENANT=foo ATL_DATABASE=foodb atl_load --preserve=ATL_DATABASE --preserve=ATL_TENANT load <multitenant_profile>"
		echo >&2
		echo >&2 "<profilename_or_partname> is any substring matching one of:"
		echo >&2
		atl_list
		echo >&2
		return 0
	}

	##################################################################################################################################
	# atl_load begins
	##################################################################################################################################

	oldtime=0
	logtime() {
		local t=$(date +%s%N)
		local tdiff=$(((t - oldtime) / 1000000))
		echo >&2 "$*: time=$tdiff"
		oldtime="$t"
	}

	#	log "atl_load $*"
	if [[ ${1:-} = global ]]; then
		echo >&2 "Loading global variables only"
		atl_unload
		oldcwd=$PWD # getprofilever and _atl_source_profiles_v* need to cd to $ATL_PROFILEDIR. We restore $oldcwd later
		profilefile=
		# Note that we don't _atl_unset_vars. 'atl load global' is invoked from /opt/atl_manage/activate in subshells when we want to preserve our parent shell's environment. FIXME: we do actually, in atl_unload. Is this a problem?
		_atl_source_profiles global "$@" || return $?
		_atl_variable_default_values "$@" || return $?
		_atl_export_vars
		cd "$oldcwd"
	elif [[ ${1:-} = none ]]; then
		atl_unload "$@"
	elif [[ ${1:-} = --help ]]; then
		_atl_load_help "$@"
	elif [[ $# = 1 ]]; then
		oldcwd=$PWD # getprofilever and _atl_source_profiles_v* need to cd to $ATL_PROFILEDIR. We restore $oldcwd later
		profilefile=
		_atl_unset_vars # Unset ATL_* vars
		#_atl_source_profiles  upgrade "$@" || return $?
		_atl_source_profiles global "$@" || return $?
		_atl_source_profiles pre "$@" || return $? # Source the profiles we're sure of ($ATL_LONGNAME, and [host=$HOSTNAME) seed variables.
		# 130ms
		_atl_variable_default_values "$@" || return $? # Set sensible defaults, based in part on the seed variables
		_atl_source_profiles post "$@" || return $?
		cd "$oldcwd"
		_atl_resolve_vars
		_atl_export_vars # Export vars even if validate_profile says we don't have the full set.
		_atl_validate_profile "$@" || {
			unset_setme_vars
			# if we're non-prod, power on - usually it's something like a database password missing when the db isn't on this host 
			if [[ $ATL_ROLE = prod ]]; then
				return 1
			fi
		} # Check our profile was sane and all vars are set. If not, unset vars marked 'setme' so their presence is noted later
		# Scripts (notably atl_start) rely on these variables being exported in order to see them, and since we can't rely on them being exported from $ATL_PROFILEDIR, do it here.

		atl_set_prompt_command
		atl_role_specific_tweaks
		case "$ATL_ROLE" in
			prod | standby | staging | sandbox )
				# atl_profile is called from atl_upgrade, and we don't want trivial problems to break it
				#run_in_background atl_check_appdeployment
				# Disable runslowqueries until we can limit it to once per session
				##atl_check_data_health --runslowqueries
				# atl_profile is called from atl_upgrade, and we don't want trivial problems to break it
				#run_in_background atl_check_data_health
				;;
		esac
		echo >&2 "$ATL_BASEURL $ATL_ROLE profile loaded"
	fi

	# Comment out since this causes strange extglob-not-set errors when called from atl_upgrade
	_atl_store_profile_timestamps
	PROFILE_TIMESTAMPS_LASTACTIVATED="${PROFILE_TIMESTAMPS:-}"
	# Note: I've commented this out as the 'disown' kill stopped jobs, like vim sessions, which is really annoying. I don't know why 'disown' on this thread would affect pre-existing stopped jobs
	# The 'disown' prevents the background process unexpectedly printing 'Done' in bash. https://stackoverflow.com/questions/7686989/running-bash-commands-in-the-background-without-printing-job-and-process-ids
	#( if [[ -w $ATL_MANAGE/.hg/dirstate ]]; then cd "$ATL_MANAGE"; hg -q pull -u; fi ) & disown

}

# Prints space-separated list of every ATL_ and JLO* variable we define, except those with passwords ('sensitive')
_atl_vars_nonsensitive() {
	# Used to end with '| xargs' but it takes 40ms, whereas 'tr' takes 1ms
	compgen -v | grep -P '^(ATL_[A-Z0-9_]+|JLOGDIR|JLOCKDIR|JLOCKDIR_GLOBAL)' | grep -vP "^${ATL_SENSITIVE_VARS:-thiswillneverexist}$" | tr '\n' ' '
	# Note: ugly inclusion of J* vars for $ATL_MANAGE/lib/jeventutils scripts, since they need to be defined for j*lock, jlog, jrun and other commands to run, and j* commands are now used extensively in cronned scripts. I don't think there's any purity reason to limit .env to ATL_* - the vars are whatever is needed for scripts to run
	# Historical note: we used to use the expression below, but 'declare' includes function definitions, which might have strings that look like variables.
	# The compgen trick is from https://stackoverflow.com/questions/1305237/how-to-list-variables-declared-in-script-in-bash/1305273
	#declare | grep -E '^(ATL_[A-Z0-9_]+|JLOGDIR|JLOCKDIR|JLOCKDIR_GLOBAL)' | grep -E -v "^${ATL_SENSITIVE_VARS:-thiswillnevereexist}" | sort | sed -e 's/^/export /g'
}

# Prints space-separated list of every ATL_ and JLO* variable we define, except those with passwords ('sensitive')
_atl_vars_sensitive() {
	compgen -v | grep -P "^${ATL_SENSITIVE_VARS:-thiswillneverexist}$" | tr '\n' ' ' || :
}

# 'Freeze' ATL variables into a .env/ 'envdir' directory within $ATL_APPDIR_BASE/$ATL_NEWVER (falling back to $ATL_APPDIR). This .env/ is then sourced by cron-driven scripts.
# atl_freeze is invoked by $ATL_MANAGE/events/upgrade-stopped-pre/atl after a new version is deployed, and $ATL_MANAGE/events/install-post/atl (the first activation script) on every reinstall, and may be invoked by hand after editing profile vars.
atl_freeze() (
	_atl_freeze_allvars() {
		local dir
		dir="$ATL_APPDIR_BASE/${ATL_NEWVER:-$ATL_VER}"
		local envdir
		envdir="$dir/.env"
		rm -rf "$envdir"
		install -d -m 755 "$envdir"
		cd "$envdir"
		ATL_VARIABLE_SOURCE="$(readlink -f "$dir")" # This lets a shell find out where these variables were set from. This is used for debugging by backupmirror/sync_backup if a required var is missing.
		echo >&2 "Populating $envdir"
		#shellcheck disable=SC2046
		for v in ${!ATL_*} ${!JLOG*} JLOCKDIR JLOCKDIR_GLOBAL; do
			echo "${!v}" >./"$v"
		done
		echo "${ATLMANAGE_PATH:?}" >./PATH # Set PATH to that set in $ATL_MANAGE/activate, not whatever rubbish the caller has in its shell
	}

	_atl_freeze_remove_irrelevant() {
		# If we're multitenant, then ATL_DATADIR and all other $ATL_TENANT_SPECIFIC_VARS variables are tenant-specific and shouldn't be persisted (see atl_tenant_freeze instead)
		if [[ ${ATL_MULTITENANT:-} == true ]]; then
			#shellcheck disable=SC2086
			rm -f ${ATL_TENANT_SPECIFIC_VARS?}
		fi
		rm -f ATL_DATADIR_NEW # Like NEWVER, this variable is transient
		rm -f ATL_NEWVER      # NEWVER is a transient variable we'd never want to persist. If it is persisted, its value overwrites that in the shell, causing problems e.g. when $ATL_APPDIR/bin/atl_event is called during an upgrade.
	}

	_atl_freeze_fixperms() {

		# Must be readable but not writable by $ATL_SERVICES_USER, which is either root or a role account in ATL_GROUP
		echo * | xargs -r chown root:"$ATL_SERVICES_GROUP" --
		if [[ -v ATL_REPLICATION_SYNCUSER ]]; then
			# This is a list of ATLvariables required by /opt/atl_manage/replication/* and monitoring scripts.
			echo ${!ATL_REPLICATION*} ATL_MONITORING ${!JLOG*} JLOCKDIR JLOCKDIR_GLOBAL ATL_MANAGE ATL_DATADIR* ATL_DATADIR_BASE* ${!ATL_APPDIR*} ATL_VER ATL_PRODUCT ATL_USER* ATL_UID ATL_GROUP ATL_GID ATL_LOCKDIR ATL_DATABASE* ATL_DATABASE_{TYPE,HOST,PORT,USER,PASSWORD}* ATL_SYSTEMD_SERVICENAME | xargs -r setfacl -m g:"$ATL_REPLICATION_SYNCUSER":r --
		fi
		if [[ -v ATL_BACKUPMIRROR_SYNCUSER ]]; then
			# Note: ATL_DATADIR_NEW is not present and not setfacl'd here, which is why we don't use ${!ATL_DATADIR*}
			echo ${!ATL_BACKUPMIRROR*} ATL_MANAGE $ATL_DATADIR $ATL_DATADIR_BASE ${!ATL_APPDIR*} ATL_VER ATL_PRODUCT ATL_USER ATL_UID ATL_GROUP ATL_GID ATL_LOCKDIR | xargs -r setfacl -m g:"$ATL_BACKUPMIRROR_SYNCUSER":r --
		fi
		# check_http_if means nagios required ATL_ROLE access
		# For Confluence, monitoring/nagios.cfg check_*_confluence_editor_online invokes atl_env for a script that needs access to these vars
		# Jethro's check_http script needs ATL_PRODUCT and ATL_MULTITENANT (/opt/atl_manage/monitoring/plugins/check_http_statuspage). Note: ATL_MULTITENANT may not exist, hence the trailing *
		# check_http_app needs ATL_BASEURL and others. This is a losing battle.
		# FIXME: we don't want to chmod TENANT_SPECIFIC_VARS, if any. Ideally we'd create a set of these, and subtract the set of tenant-specific vars, but bash is too crappy, so we just append * to those we know of like ATL_BASEURL
		shopt -s nullglob # for ATL_MULTITENANT* which may not exist
		id -u nagios >/dev/null || { echo >&2 "Please run atl_install_monitoring first"; return 1; }
		echo ATL_MANAGE ATL_PRODUCT ATL_APPDOMAIN* ATL_FQDN* ATL_USER* ATL_DATABASE* ATL_MULTITENANT* ATL_SYSTEMD_SERVICENAME ATL_ROLE ATL_BASEURL* ATL_BASEURL_IS_AUTH_PROXIED* ATL_BASEURL_INTERNAL* | xargs setfacl -m u:nagios:r --
		# The 2>/dev/null etc is because ATL_LONGNAME doesn't exist when asne.easyjethro.com.au is sourced (which puts ATL_LONGNAME in ATL_TENANT_SPECIFIC_VARS)
		echo ATL_MANAGE ATL_APPDIR ATL_DATADIR_BASE ATL_DATABASE_TYPE ATL_DATABASE_HOST ATL_DATABASE_PORT ATL_MONITORING JLOCKDIR JLOCKDIR_GLOBAL JLOG* PATH ATL_MONITORING_TYPES ATL_LONGNAME ATL_SHORTNAME | xargs chmod o+r -- 2>/dev/null || : # Non-sensitive vars we might want e.g. ATL_TENANT cronjobs access
		_atl_vars_sensitive | xargs chown root:root --
		_atl_vars_sensitive | xargs setfacl -bn --
		# Remove perms granted to nagios, for example
		# Note that the app runtime user, $ATL_USER, does not have permission to read any of these files. Anything it needs will have been baked into conf/server.xml or bin/setenv.sh at deploy time. The invoker of atl_env will be ATL_SERVICES_USER, not ATL_USER
	}

	_atl_freeze_scriptlinks() {
		# Previously we had $ATL_APPDIR/bin/atl_{env,psql,...} scripts, that differed from $ATL_MANAGE/bin/atl_.. only in that they were contextualized for the app. Soo.. it makes sense to put the scripts in .env/ alongside the contextualizing vars.
		ln -sf "$ATL_MANAGE/lib/atl_env" atl_env
		ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" atl_event
		case "$ATL_DATABASE_TYPE" in
		mysql)
			ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" atl_mysql
			ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" atl_mysql
			;;
		postgresql*)
			ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" atl_psql
			ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" atl_pg_dump
			;;
		esac
	}

	[[ -v ATL_SHORTNAME ]] || error "No app profile selected. Use 'atl profile load' to pick one: \n$(atl_profile list)"
	_atl_freeze_allvars
	_atl_freeze_remove_irrelevant
	_atl_freeze_fixperms
	_atl_freeze_scriptlinks
)

_atl_tenant_freeze() {
	[[ ${ATL_MULTITENANT:-} = true ]] || {
		echo >&2 "_atl_tenant_freeze should only be called for multitenant apps"
		return 1
	}
	[[ -v ATL_TENANT ]] || { echo >&2 "_atl_tenant_freeze should only be called when ATL_TENANT is set"; }

	# We assume that being multitenant, ATL_USER, ATL_DATADIR and other ATL_TENANT_SPECIFIC_VARS are tenant-specific
	install -d -o root -g "$ATL_USER" -m 750 "$ATL_DATADIR/.env"
	chmod g+s "$ATL_DATADIR/.env"
	for v in $ATL_TENANT_SPECIFIC_VARS; do
		echo "${!v}" >"$ATL_DATADIR"/.env/"$v"
	done
	rm -f "$ATL_DATADIR"/.env/atl_env
	# Unlike atl_freeze, we can't just symlink to $ATL_MANAGE/lib/atl_env, because we want to use --envdir twice to load our tenant .env/ATL_* and our app-wide .env/ATL_*
	# Note we refer to $ATL_APPDIR_BASE/current, not $ATL_APPDIR which hardcodes the version. This means that when the app is upgraded, tenant-specific scripts see the new app variables, not the old. 
	echo -e "#!/bin/bash\n# Wrapper script that defines ATL_* variables correctly for tenant $ATL_TENANT\n# We first load generic $ATL_SHORTNAME ATL vars from \$ATL_APPDIR/.env, then tenant-specific vars (possibly overriding generic ones).\n# Used by /etc/cron.d/$ATL_SHORTNAME-$ATL_TENANT-* cron scripts\n# Created by ${BASH_SOURCE[0]} on $(date)\n\n. $ATL_MANAGE/lib/atl_env --envdir=\"$ATL_APPDIR_BASE/current/.env\" --envdir=\"$ATL_DATADIR_BASE/$ATL_TENANT/.env\" \"\$@\"" >"$ATL_DATADIR"/.env/atl_env
	# Nagios needs rx. It doesn't hurt to grant everyone rx, as the .env/ATL_* files are permissioned
	chmod ugo+rx "$ATL_DATADIR"/.env/atl_env

	case "$ATL_DATABASE_TYPE" in
	mysql)
		ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" "$ATL_DATADIR"/.env/atl_mysql
		ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" "$ATL_DATADIR"/.env/atl_mysqldump
		;;
	postgresql)
		ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" "$ATL_DATADIR"/.env/atl_psql
		ln -sf "$ATL_MANAGE/lib/atl_contextualized_command.sh" "$ATL_DATADIR"/.env/atl_pg_dump
		;;
	esac
	id -u nagios >/dev/null || { echo >&2 "Please run atl_install_monitoring first"; return 1; }
	setfacl -R -m u:nagios:rX "$ATL_DATADIR" "$ATL_DATADIR/.env"
}

_atl_unset_vars() {
	# Unset every variable beginning with ATL_
	# https://stackoverflow.com/questions/1305237/how-to-list-variables-declared-in-script-in-bash

	# Actually, some ATL_* vars must survive, notably ATL_MANAGE and ATL_PROFILEDIR which are needed for bootstrapping:
	# Preserve ATL_TENANT_SPECIFIC_VARS for the EJ case where a global profile is loaded, then admin.easyjethro.com.au profile is loaded and somehow doesn't source profile.sh
	preserved_vars=(ATL_MANAGE ATL_PROFILEDIR "${!ATL_TENANT*}")
	# We also let the caller specify variables to preserve with the --preserve flag, which stores a list in ${preserved_vars[@]}.
	# A custom atl_load in a multi-tenant app might use --preserve to pre-set ATL_DATABASE
	# shellcheck disable=SC2001
	ignoredvars="^($(echo "${preserved_vars[@]}" | sed -e 's/ /|/g'))="
	#log "Ignoring pattern: $ignoredvars"
	# shellcheck disable=SC2046
	unset $( (
		set -o posix
		set
	) | grep -Pv "$ignoredvars" | grep "^ATL_[_A-Z0-9]\\+=" | sed -e 's/=.*//' | xargs)
	#	unset PROMPT_COMMAND
	# Unfortunately the original PS1 is lost. Set it to the default from /etc/bash.bashrc
	# shellcheck disable=SC2154
	export PS1='${debian_chroot:+($debian_chroot)}\u@\h:\w\$ '

}

atl_list() {
	test -d "$ATL_PROFILEDIR" && (
		# If we don't have rx permission, or if someone else goes wrong, fail
		set -eu
		cd "$ATL_PROFILEDIR"
		# Find profile files, ignore mercurial, plugindata and [foo=bar] selector files. Print just the filename ignoring any subdirectory names.
		# Keep this code roughly in sync with the other 'iwholename' occurrence below in _atl_store_profile_timestamps
		find -L . -not -iwholename "*.hg*" -not -iwholename "*/plugindata/*" -not -iwholename "*/licenses/*" -not -name .meta -not -iwholename "*\[*\]*" -type f -printf "%f\n"
		# Doesn't work as extglob or whatever isn't enabled at this point
		#ls -1 !(default|*.txt|plugindata)
	)
}

# Switch to a different version. Used to switch to ATL_NEWVER in scripts like atl_deploy
_atl_setversion() {
	is_valid_version_pattern "$1" || error "Usage: _atl_setversion <ver> ('$1' is not a valid version)"
	echo >&2 "We're about to switch to version $1, via awful hacky bash, sourcing the following:"
	# FIXME: A saner way of doing this would be to store a 'template' form of each composite ATL_* variable, allowing it to be recalculated when a part, such as $ATL_VER, changes. But this works
	declare -p | grep "^declare -x ATL_.\+=.*$ATL_VER" | sed -e "s/$ATL_VER/$1/g"
	set -x
	eval "$(declare -p | grep "^declare -x ATL_.\+=.*$ATL_VER" | sed -e "s/$ATL_VER/$1/g")"
	echo "Afterwards, ATL_VER is $ATL_VER"
	set +x

}

## A function to source manually, only when installing new gems for the ATL_MANAGE environment. Normally the user's rbenv (if set) should take precedence, so this isn't automatically sourced
#atl_ruby_developer_environment()
#{
#	export RBENV_ROOT="$ATL_MANAGE/lib/ruby/rbenv"
#	export RBENV_DIR=$ATL_MANAGE  # Start searching for .ruby-version files here
#	export PATH="$RBENV_ROOT"/bin:"$PATH"
#	eval "$(rbenv init -)"
#	#shellcheck source= /opt/atl_manage/lib/ruby/rbenv/completions/rbenv.bash
#	. "$RBENV_ROOT"/completions/rbenv.bash
#	rbenv rehash
#	# Gems normally go in a ruby-version-specific directory. This could be overridden with:
#	#export GEM_HOME=$ATL_MANAGE/lib/ruby/gems
#}

# Set $PROFILE_TIMESTAMPS to a list of all 'modified' timestamps of profile files
_atl_store_profile_timestamps() {
	# requires extglob to be set.
	# Note that this requires extglob to be set in the caller, otherwise we get an error, syntax error near unexpected token `('
	# 14/Jan/23: I don't think we need extglob any more
	# Keep this roughly in sync with the equivalent find in list()
	#[[ -r "$ATL_PROFILEDIR" ]]
	# Emit a timestamp
	PROFILE_TIMESTAMPS="$(find -L "$ATL_PROFILEDIR" -not -iwholename "*.hg*" -not -iwholename "*/plugindata/*" -not -name .meta -type f -printf "%t ")"
}

# FIXME: This is fundamentally hideous and broken. The ATL_NEWVER / ATL_VER we change might not even be for our app, if a shell script like ./common.sh is symlinked
_atl_upgrade_profile() {
	# shellcheck disable=SC2206    # unquoted so the space-separated fields become entries
	echo >&2 "Setting upgraded ATL_VER=$ATL_NEWVER in $ATL_PROFILEFILES_SOURCED_ABSOLUTE"
	#shellcheck disable=SC2206
	if [[ -n $ATL_PROFILEFILES_SOURCED ]]; then
		#shellcheck disable=SC2086,SC2046
		perl -i -pe "s/^(\s*)ATL_NEWVER=['\"]?\Q$ATL_NEWVER\E['\"]?$/\1ATL_VER=$ATL_NEWVER/" ${ATL_PROFILEFILES_SOURCED_ABSOLUTE}
		if [[ -v ATL_NEWVER_HASH ]]; then
			#shellcheck disable=SC2086,SC2046
			perl -i -pe "s/^(\s*)ATL_NEWVER_HASH=\Q$ATL_NEWVER_HASH\E$/\1ATL_VER_HASH=$ATL_NEWVER_HASH/" ${ATL_PROFILEFILES_SOURCED_ABSOLUTE}
		fi
		set +x
	else
		error "Something went wrong: ATL_PROFILEFILES_SOURCED should contain a list of files in $ATL_PROFILEDIR sourced to contribute to our ATL_ variables, but it is empty. Normally we would update ATL_VER in those files at this point"
	fi
}

# FIXME: This is fundamentally hideous and broken. The ATL_NEWVER / ATL_VER we change might not even be for our app, if a shell script like ./common.sh is symlinked
_atl_downgrade_profile() {
	# shellcheck disable=SC2206    # note, unquoted so the space-separated fields become entries
	if [[ -n $ATL_PROFILEFILES_SOURCED ]]; then
		echo >&2 "Setting downgraded ATL_VER=$ATL_VER in $ATL_PROFILEFILES_SOURCED_ABSOLUTE"
		set -x
		[[ -n "$ATL_PROFILEFILES_SOURCED_ABSOLUTE" ]] || { echo >&2 "Unset var"; return 1; }
		# Run substitution on all non-dot files, plus all files beginning with '.' except '.', '..' and '.hg'
		# https://unix.stackexchange.com/questions/186214/how-to-match-with-hidden-files-inside-a-directory
		# Remove any ATL_NEWVER, and rename ATL_VER to ATL_NEWVER.
		#shellcheck disable=SC2086
		# This is not necessary for downgrades, is it?? Comment out, as it clobbers unrelated content and loses trailing ';;' in case statements.
		#perl -i -pe 's/^(\s*)ATL_NEWVER=.*//' ${ATL_PROFILEFILES_SOURCED_ABSOLUTE}
		#shellcheck disable=SC2086
		perl -i -pe "s/^(\s*)ATL_VER=['\"]?\Q$ATL_VER\E['\"]?$/\1ATL_NEWVER=$ATL_VER/" ${ATL_PROFILEFILES_SOURCED_ABSOLUTE}
		if [[ -v ATL_VER_HASH ]]; then
			#shellcheck disable=SC2086,SC2046
			perl -i -pe "s/^(\s*)ATL_VER_HASH=['\"]?\Q$ATL_VER_HASH\E['\"]?$/\1ATL_NEWVER_HASH=$ATL_VER_HASH/" ${ATL_PROFILEFILES_SOURCED_ABSOLUTE}
		fi
		set +x
	else
		error "Something went wrong: ATL_PROFILEFILES_SOURCED should contain a list of files in $ATL_PROFILEDIR sourced to contribute to our ATL_ variables, but it is empty. Normally we would update ATL_VER in those files at this point"
	fi
}

atl_grep() {
	set | grep "^ATL_$*"
}

[[ $(type -t log) = function ]] || log() { echo "$*"; } # We haven't sourced logging.sh at this point
# https://stackoverflow.com/questions/13588457/forward-declarations-in-bash

# Export these functions so they can be inherited by subshells. This lets the caller write scripts that call e.g. 'atl_list' (or 'atl list'), which should work from subshells just like invoking an atl_* script would. EDIT: replaced by 'set -a'. EDIT: reinstated since 'set -a' breaks subshells after autocomplete
export -f atl_freeze _atl_tenant_freeze atl_list atl_load atl_unload _atl_unset_vars _getprofilepath _atl_store_profile_timestamps _atl_setversion _atl_vars_sensitive

#alias atl_edit='source "$ATL_MANAGE"/bin/atl_editprofile'
#alias atl_editprofile='source "$ATL_MANAGE"/bin/atl_editprofile'
#alias atl_upgrade='source "$ATL_MANAGE"/bin/atl_upgrade'
alias cdm='cd "$ATL_MANAGE"'
alias cdp='[[ -d "$ATL_PROFILEDIR/$ATL_ORGANIZATION" ]] && cd "$ATL_PROFILEDIR/$ATL_ORGANIZATION" || cd "$ATL_PROFILEDIR"'
alias cda='cd "$ATL_APPDIR"; readlink -f .'
alias cdal='cd "$ATL_APPDIR/${ATL_TOMCAT_SUBDIR}logs"; readlink -f .'
alias cdale='cd "$ATL_APPDIR/${ATL_TOMCAT_SUBDIR}logs/events"; readlink -f .'
alias cdab='cd "$ATL_APPDIR_BASE"'
alias cdan='cd "$ATL_APPDIR_BASE/${ATL_NEWVER:-current}"; readlink -f .'
alias cdd='cd "$ATL_DATADIR"; readlink -f .'
alias cddb='cd "$ATL_DATADIR_BASE"'
alias cddn='cd "$ATL_DATADIR_NEW"; readlink -f .'
alias cdwl='cd "/var/log/$ATL_WEBSERVER/$ATL_LONGNAME"; readlink -f .'
alias cddl='cd "$ATL_DATALOGDIR"; readlink -f .'
alias cdbm='cd "${ATL_BACKUPMIRROR_DESTINATION_BACKUP_ROOT:?undefined (backupmirror not enabled)}"'
# If the -c (--current) flag was used with atl_install/atl_patchqueue, then the 'workingcopy' directory embeds $ATL_VER, not $ATL_NEWVER, so it's not clear which working directory to prefer
# This alias tests for the $ATL_NEWVER variant first, and if not present falls back to $ATL_VER variant
alias cdwc='_wcdir=$ATL_APPDIR_BASE && test -d $_wcdir/${ATL_NEWVER}-workingcopy && cd $_wcdir/${ATL_NEWVER}-workingcopy || cd $ATL_APPDIR_BASE/${ATL_VER}-workingcopy'
alias cdcwc='cd $ATL_APPDIR_BASE/${ATL_VER}-workingcopy'
alias cdb='cd $ATL_BACKUP_ROOT'
_lastinterval=hourly.0
# Usually our smallest rsnapshot interval is 'hourly', but it could be customized
if [[ -f ${ATL_APPDIR:-}/backups/rsnapshot.conf ]]; then _lastinterval="$(cat "$ATL_APPDIR"/backups/rsnapshot.conf | awk '/^interval/ { print $2".0"; exit; }')"; fi
#shellcheck disable=SC2139
alias cdb0='cd "$ATL_BACKUP_ROOT"/'"$_lastinterval"
alias cdb0d='cd "$ATL_BACKUP_ROOT"/'"$_lastinterval/database"
#shellcheck disable=SC2139
alias cdbm0='cd "${ATL_BACKUPMIRROR_DESTINATION_BACKUP_ROOT:?undefined (backupmirror not enabled)}"/'"$_lastinterval"
alias cdl='cd $ATL_LOGDIR'
alias ARB='atl_reinstall --rebase'

# vim: set filetype=sh foldmethod=marker formatoptions+=cro :
